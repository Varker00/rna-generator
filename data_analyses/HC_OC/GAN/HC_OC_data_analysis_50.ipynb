{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import DBSCAN\n",
    "import umap\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_training = pd.read_csv('../../../classifier_data/HC_training.csv', sep='\\t').T\n",
    "hc_test = pd.read_csv('../../../classifier_data/HC_test.csv', sep='\\t').T\n",
    "oc_training = pd.read_csv('../../../classifier_data/OC_training.csv', sep='\\t').T\n",
    "oc_test = pd.read_csv('../../../classifier_data/OC_test.csv', sep='\\t').T\n",
    "\n",
    "synthetic_hc_data_path = '../../../best_models/HC/GAN/50/synthetic_data/'\n",
    "model_id = os.listdir(synthetic_hc_data_path)[0]\n",
    "hc_synthetic = pd.read_csv(f'{synthetic_hc_data_path}/{model_id}/generated_data.tsv', sep='\\t')\n",
    "\n",
    "synthetic_oc_data_path = '../../../best_models/OC/GAN/50/synthetic_data/'\n",
    "model_id = os.listdir(synthetic_oc_data_path)[0]\n",
    "oc_synthetic = pd.read_csv(f'{synthetic_oc_data_path}/{model_id}/generated_data.tsv', sep='\\t')\n",
    "\n",
    "# combine training and test data with labels\n",
    "hc_training['label'] = 'HC'\n",
    "hc_test['label'] = 'HC'\n",
    "oc_training['label'] = 'OC'\n",
    "oc_test['label'] = 'OC'\n",
    "\n",
    "hc_synthetic['label'] = 'HC'\n",
    "oc_synthetic['label'] = 'OC'\n",
    "\n",
    "training_data = pd.concat([hc_training, oc_training])\n",
    "test_data = pd.concat([hc_test, oc_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ENSG00000081237', 'ENSG00000085265', 'ENSG00000090382',\n",
       "       'ENSG00000110719', 'ENSG00000115523', 'ENSG00000119535',\n",
       "       'ENSG00000137642', 'ENSG00000160255', 'ENSG00000177359',\n",
       "       'ENSG00000198336', 'ENSG00000240356', 'ENSG00000244734',\n",
       "       'ENSG00000257207', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only the columns that are in both datasets\n",
    "# Znalezienie wspólnych kolumn\n",
    "common_columns = training_data.columns.intersection(test_data.columns)\n",
    "common_columns = common_columns.intersection(hc_synthetic.columns)\n",
    "common_columns = common_columns.intersection(oc_synthetic.columns)\n",
    "\n",
    "# Uporządkowanie kolumn w real_data\n",
    "training_data = training_data[common_columns]\n",
    "\n",
    "# Uporządkowanie kolumn w synthetic_data\n",
    "test_data = test_data[common_columns]\n",
    "\n",
    "# Uporządkowanie kolumn w synthetic_data\n",
    "hc_synthetic = hc_synthetic[common_columns]\n",
    "oc_synthetic = oc_synthetic[common_columns]\n",
    "\n",
    "common_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000081237</th>\n",
       "      <th>ENSG00000085265</th>\n",
       "      <th>ENSG00000090382</th>\n",
       "      <th>ENSG00000110719</th>\n",
       "      <th>ENSG00000115523</th>\n",
       "      <th>ENSG00000119535</th>\n",
       "      <th>ENSG00000137642</th>\n",
       "      <th>ENSG00000160255</th>\n",
       "      <th>ENSG00000177359</th>\n",
       "      <th>ENSG00000198336</th>\n",
       "      <th>ENSG00000240356</th>\n",
       "      <th>ENSG00000244734</th>\n",
       "      <th>ENSG00000257207</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VUMC-HC-0033-TR2591</th>\n",
       "      <td>6.121758</td>\n",
       "      <td>4.078496</td>\n",
       "      <td>4.643048</td>\n",
       "      <td>4.169415</td>\n",
       "      <td>5.849773</td>\n",
       "      <td>4.399111</td>\n",
       "      <td>4.643048</td>\n",
       "      <td>4.796726</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>7.670810</td>\n",
       "      <td>3.535280</td>\n",
       "      <td>6.995484</td>\n",
       "      <td>9.847484</td>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vumc-HD-70-TR1062</th>\n",
       "      <td>9.448584</td>\n",
       "      <td>4.926369</td>\n",
       "      <td>5.721557</td>\n",
       "      <td>5.309622</td>\n",
       "      <td>7.717082</td>\n",
       "      <td>4.219669</td>\n",
       "      <td>6.106566</td>\n",
       "      <td>7.143903</td>\n",
       "      <td>5.079361</td>\n",
       "      <td>7.237932</td>\n",
       "      <td>3.701701</td>\n",
       "      <td>10.021953</td>\n",
       "      <td>8.262227</td>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VUMC-HC0053-DOT-HD-48h-TR3087</th>\n",
       "      <td>7.317863</td>\n",
       "      <td>4.845811</td>\n",
       "      <td>4.997802</td>\n",
       "      <td>5.151550</td>\n",
       "      <td>5.593316</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>4.559495</td>\n",
       "      <td>5.935819</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.720811</td>\n",
       "      <td>7.783065</td>\n",
       "      <td>7.050183</td>\n",
       "      <td>8.831693</td>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vumc-HD-149-TR932</th>\n",
       "      <td>5.552469</td>\n",
       "      <td>4.492627</td>\n",
       "      <td>4.275620</td>\n",
       "      <td>3.544794</td>\n",
       "      <td>5.451417</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>4.753784</td>\n",
       "      <td>3.544794</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>9.503594</td>\n",
       "      <td>8.661739</td>\n",
       "      <td>3.647372</td>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vumc-HD-36-TR1165</th>\n",
       "      <td>9.002749</td>\n",
       "      <td>6.525333</td>\n",
       "      <td>5.811822</td>\n",
       "      <td>7.579274</td>\n",
       "      <td>7.306126</td>\n",
       "      <td>5.743631</td>\n",
       "      <td>5.998264</td>\n",
       "      <td>6.846139</td>\n",
       "      <td>4.172174</td>\n",
       "      <td>7.438673</td>\n",
       "      <td>5.671874</td>\n",
       "      <td>9.877834</td>\n",
       "      <td>3.862107</td>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>5.216010</td>\n",
       "      <td>4.404345</td>\n",
       "      <td>4.973923</td>\n",
       "      <td>4.852151</td>\n",
       "      <td>6.123772</td>\n",
       "      <td>4.213976</td>\n",
       "      <td>4.074963</td>\n",
       "      <td>5.310466</td>\n",
       "      <td>5.851544</td>\n",
       "      <td>3.883828</td>\n",
       "      <td>6.668383</td>\n",
       "      <td>8.034715</td>\n",
       "      <td>6.958013</td>\n",
       "      <td>OC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>10.710587</td>\n",
       "      <td>10.352650</td>\n",
       "      <td>9.451887</td>\n",
       "      <td>9.523185</td>\n",
       "      <td>9.438555</td>\n",
       "      <td>6.076378</td>\n",
       "      <td>7.515854</td>\n",
       "      <td>10.496648</td>\n",
       "      <td>3.997873</td>\n",
       "      <td>3.523791</td>\n",
       "      <td>8.857549</td>\n",
       "      <td>10.313637</td>\n",
       "      <td>3.307666</td>\n",
       "      <td>OC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>5.439116</td>\n",
       "      <td>4.961877</td>\n",
       "      <td>4.416364</td>\n",
       "      <td>4.786206</td>\n",
       "      <td>5.912365</td>\n",
       "      <td>3.806074</td>\n",
       "      <td>4.076955</td>\n",
       "      <td>5.422790</td>\n",
       "      <td>9.764086</td>\n",
       "      <td>5.734484</td>\n",
       "      <td>4.502339</td>\n",
       "      <td>9.193785</td>\n",
       "      <td>5.114867</td>\n",
       "      <td>OC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>5.569016</td>\n",
       "      <td>4.002475</td>\n",
       "      <td>3.721914</td>\n",
       "      <td>5.104712</td>\n",
       "      <td>7.255627</td>\n",
       "      <td>4.165480</td>\n",
       "      <td>4.986170</td>\n",
       "      <td>5.447999</td>\n",
       "      <td>4.587697</td>\n",
       "      <td>3.212327</td>\n",
       "      <td>5.404073</td>\n",
       "      <td>9.459144</td>\n",
       "      <td>9.778724</td>\n",
       "      <td>OC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>7.289435</td>\n",
       "      <td>5.084757</td>\n",
       "      <td>5.458520</td>\n",
       "      <td>6.732266</td>\n",
       "      <td>6.983347</td>\n",
       "      <td>5.624267</td>\n",
       "      <td>5.666443</td>\n",
       "      <td>7.006332</td>\n",
       "      <td>6.215683</td>\n",
       "      <td>6.541802</td>\n",
       "      <td>7.682019</td>\n",
       "      <td>9.177794</td>\n",
       "      <td>4.711522</td>\n",
       "      <td>OC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>556 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ENSG00000081237  ENSG00000085265  \\\n",
       "VUMC-HC-0033-TR2591                   6.121758         4.078496   \n",
       "Vumc-HD-70-TR1062                     9.448584         4.926369   \n",
       "VUMC-HC0053-DOT-HD-48h-TR3087         7.317863         4.845811   \n",
       "Vumc-HD-149-TR932                     5.552469         4.492627   \n",
       "Vumc-HD-36-TR1165                     9.002749         6.525333   \n",
       "...                                        ...              ...   \n",
       "76                                    5.216010         4.404345   \n",
       "77                                   10.710587        10.352650   \n",
       "78                                    5.439116         4.961877   \n",
       "79                                    5.569016         4.002475   \n",
       "80                                    7.289435         5.084757   \n",
       "\n",
       "                               ENSG00000090382  ENSG00000110719  \\\n",
       "VUMC-HC-0033-TR2591                   4.643048         4.169415   \n",
       "Vumc-HD-70-TR1062                     5.721557         5.309622   \n",
       "VUMC-HC0053-DOT-HD-48h-TR3087         4.997802         5.151550   \n",
       "Vumc-HD-149-TR932                     4.275620         3.544794   \n",
       "Vumc-HD-36-TR1165                     5.811822         7.579274   \n",
       "...                                        ...              ...   \n",
       "76                                    4.973923         4.852151   \n",
       "77                                    9.451887         9.523185   \n",
       "78                                    4.416364         4.786206   \n",
       "79                                    3.721914         5.104712   \n",
       "80                                    5.458520         6.732266   \n",
       "\n",
       "                               ENSG00000115523  ENSG00000119535  \\\n",
       "VUMC-HC-0033-TR2591                   5.849773         4.399111   \n",
       "Vumc-HD-70-TR1062                     7.717082         4.219669   \n",
       "VUMC-HC0053-DOT-HD-48h-TR3087         5.593316         3.083092   \n",
       "Vumc-HD-149-TR932                     5.451417         3.083092   \n",
       "Vumc-HD-36-TR1165                     7.306126         5.743631   \n",
       "...                                        ...              ...   \n",
       "76                                    6.123772         4.213976   \n",
       "77                                    9.438555         6.076378   \n",
       "78                                    5.912365         3.806074   \n",
       "79                                    7.255627         4.165480   \n",
       "80                                    6.983347         5.624267   \n",
       "\n",
       "                               ENSG00000137642  ENSG00000160255  \\\n",
       "VUMC-HC-0033-TR2591                   4.643048         4.796726   \n",
       "Vumc-HD-70-TR1062                     6.106566         7.143903   \n",
       "VUMC-HC0053-DOT-HD-48h-TR3087         4.559495         5.935819   \n",
       "Vumc-HD-149-TR932                     3.083092         4.753784   \n",
       "Vumc-HD-36-TR1165                     5.998264         6.846139   \n",
       "...                                        ...              ...   \n",
       "76                                    4.074963         5.310466   \n",
       "77                                    7.515854        10.496648   \n",
       "78                                    4.076955         5.422790   \n",
       "79                                    4.986170         5.447999   \n",
       "80                                    5.666443         7.006332   \n",
       "\n",
       "                               ENSG00000177359  ENSG00000198336  \\\n",
       "VUMC-HC-0033-TR2591                   3.083092         7.670810   \n",
       "Vumc-HD-70-TR1062                     5.079361         7.237932   \n",
       "VUMC-HC0053-DOT-HD-48h-TR3087         3.083092         3.720811   \n",
       "Vumc-HD-149-TR932                     3.544794         3.083092   \n",
       "Vumc-HD-36-TR1165                     4.172174         7.438673   \n",
       "...                                        ...              ...   \n",
       "76                                    5.851544         3.883828   \n",
       "77                                    3.997873         3.523791   \n",
       "78                                    9.764086         5.734484   \n",
       "79                                    4.587697         3.212327   \n",
       "80                                    6.215683         6.541802   \n",
       "\n",
       "                               ENSG00000240356  ENSG00000244734  \\\n",
       "VUMC-HC-0033-TR2591                   3.535280         6.995484   \n",
       "Vumc-HD-70-TR1062                     3.701701        10.021953   \n",
       "VUMC-HC0053-DOT-HD-48h-TR3087         7.783065         7.050183   \n",
       "Vumc-HD-149-TR932                     9.503594         8.661739   \n",
       "Vumc-HD-36-TR1165                     5.671874         9.877834   \n",
       "...                                        ...              ...   \n",
       "76                                    6.668383         8.034715   \n",
       "77                                    8.857549        10.313637   \n",
       "78                                    4.502339         9.193785   \n",
       "79                                    5.404073         9.459144   \n",
       "80                                    7.682019         9.177794   \n",
       "\n",
       "                               ENSG00000257207 label  \n",
       "VUMC-HC-0033-TR2591                   9.847484    HC  \n",
       "Vumc-HD-70-TR1062                     8.262227    HC  \n",
       "VUMC-HC0053-DOT-HD-48h-TR3087         8.831693    HC  \n",
       "Vumc-HD-149-TR932                     3.647372    HC  \n",
       "Vumc-HD-36-TR1165                     3.862107    HC  \n",
       "...                                        ...   ...  \n",
       "76                                    6.958013    OC  \n",
       "77                                    3.307666    OC  \n",
       "78                                    5.114867    OC  \n",
       "79                                    9.778724    OC  \n",
       "80                                    4.711522    OC  \n",
       "\n",
       "[556 rows x 14 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add synthetic data to training data\n",
    "training_data_synthetic = pd.concat([training_data, hc_synthetic, oc_synthetic])\n",
    "training_data_synthetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wykorzystanie klasyfikatorów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność: 0.7513513513513513\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.79      0.89      0.84       131\n",
      "          OC       0.61      0.41      0.49        54\n",
      "\n",
      "    accuracy                           0.75       185\n",
      "   macro avg       0.70      0.65      0.66       185\n",
      "weighted avg       0.73      0.75      0.73       185\n",
      "\n",
      "[[117  14]\n",
      " [ 32  22]]\n",
      "Dokładność: 0.7567567567567568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.78      0.91      0.84       131\n",
      "          OC       0.64      0.39      0.48        54\n",
      "\n",
      "    accuracy                           0.76       185\n",
      "   macro avg       0.71      0.65      0.66       185\n",
      "weighted avg       0.74      0.76      0.74       185\n",
      "\n",
      "[[119  12]\n",
      " [ 33  21]]\n"
     ]
    }
   ],
   "source": [
    "# klasyfikacja z uyciem svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def svm_classification(training_data, test_data):\n",
    "    # Oddziel etykiety od cech\n",
    "    X_train = training_data.drop('label', axis=1)\n",
    "    y_train = training_data['label']\n",
    "    X_test = test_data.drop('label', axis=1)\n",
    "    y_test = test_data['label']\n",
    "\n",
    "    # Normalizacja danych\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Klasyfikacja przy użyciu SVM\n",
    "    svm = SVC(kernel='linear', random_state=42)\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred = svm.predict(X_test)\n",
    "\n",
    "    # Wypisanie dokładności i innych metryk\n",
    "    print(f\"Dokładność: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "svm_classification(training_data, test_data)\n",
    "svm_classification(training_data_synthetic, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność: 0.7027027027027027\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.81      0.76      0.78       131\n",
      "          OC       0.49      0.56      0.52        54\n",
      "\n",
      "    accuracy                           0.70       185\n",
      "   macro avg       0.65      0.66      0.65       185\n",
      "weighted avg       0.71      0.70      0.71       185\n",
      "\n",
      "[[100  31]\n",
      " [ 24  30]]\n",
      "Dokładność: 0.6756756756756757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.81      0.71      0.76       131\n",
      "          OC       0.46      0.59      0.52        54\n",
      "\n",
      "    accuracy                           0.68       185\n",
      "   macro avg       0.63      0.65      0.64       185\n",
      "weighted avg       0.71      0.68      0.69       185\n",
      "\n",
      "[[93 38]\n",
      " [22 32]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# klasyfikacja z uyciem random forest\n",
    "def decision_tree_classification(training_data, test_data):\n",
    "    # Oddziel etykiety od cech\n",
    "    X_train = training_data.drop('label', axis=1)\n",
    "    y_train = training_data['label']\n",
    "    X_test = test_data.drop('label', axis=1)\n",
    "    y_test = test_data['label']\n",
    "\n",
    "    # Normalizacja danych\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Klasyfikacja\n",
    "    dt = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "    dt.fit(X_train, y_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "\n",
    "    # Wypisanie dokładności i innych metryk\n",
    "    print(f\"Dokładność: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "decision_tree_classification(training_data, test_data)\n",
    "decision_tree_classification(training_data_synthetic, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność: 0.7621621621621621\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.76      0.96      0.85       131\n",
      "          OC       0.75      0.28      0.41        54\n",
      "\n",
      "    accuracy                           0.76       185\n",
      "   macro avg       0.76      0.62      0.63       185\n",
      "weighted avg       0.76      0.76      0.72       185\n",
      "\n",
      "[[126   5]\n",
      " [ 39  15]]\n",
      "Dokładność: 0.7621621621621621\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.77      0.95      0.85       131\n",
      "          OC       0.71      0.31      0.44        54\n",
      "\n",
      "    accuracy                           0.76       185\n",
      "   macro avg       0.74      0.63      0.64       185\n",
      "weighted avg       0.75      0.76      0.73       185\n",
      "\n",
      "[[124   7]\n",
      " [ 37  17]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# klasyfikacja z uyciem random forest\n",
    "def random_forest_classification(training_data, test_data):\n",
    "    # Oddziel etykiety od cech\n",
    "    X_train = training_data.drop('label', axis=1)\n",
    "    y_train = training_data['label']\n",
    "    X_test = test_data.drop('label', axis=1)\n",
    "    y_test = test_data['label']\n",
    "\n",
    "    # Normalizacja danych\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Klasyfikacja\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # Wypisanie dokładności i innych metryk\n",
    "    print(f\"Dokładność: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "random_forest_classification(training_data, test_data)\n",
    "random_forest_classification(training_data_synthetic, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność: 0.7675675675675676\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84       131\n",
      "           1       0.64      0.46      0.54        54\n",
      "\n",
      "    accuracy                           0.77       185\n",
      "   macro avg       0.72      0.68      0.69       185\n",
      "weighted avg       0.75      0.77      0.76       185\n",
      "\n",
      "[[117  14]\n",
      " [ 29  25]]\n",
      "Dokładność: 0.7405405405405405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       131\n",
      "           1       0.56      0.50      0.53        54\n",
      "\n",
      "    accuracy                           0.74       185\n",
      "   macro avg       0.68      0.67      0.68       185\n",
      "weighted avg       0.73      0.74      0.74       185\n",
      "\n",
      "[[110  21]\n",
      " [ 27  27]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# klasyfikacja z uyciem xgboost\n",
    "def xgboost_classification(training_data, test_data):\n",
    "    # Oddziel etykiety od cech\n",
    "    X_train = training_data.drop('label', axis=1)\n",
    "    y_train = training_data['label']\n",
    "    X_test = test_data.drop('label', axis=1)\n",
    "    y_test = test_data['label']\n",
    "\n",
    "    # Normalizacja danych\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Klasyfikacja\n",
    "    y_train = y_train.replace('HC', 0)\n",
    "    y_train = y_train.replace('OC', 1)\n",
    "    y_test = y_test.replace('HC', 0)\n",
    "    y_test = y_test.replace('OC', 1)\n",
    "    xgb = XGBClassifier(random_state=42)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred = xgb.predict(X_test)\n",
    "\n",
    "    # Wypisanie dokładności i innych metryk\n",
    "    print(f\"Dokładność: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "xgboost_classification(training_data, test_data)\n",
    "xgboost_classification(training_data_synthetic, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\anaconda3\\envs\\poop\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność: 0.7621621621621621\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.84      0.82      0.83       131\n",
      "          OC       0.59      0.63      0.61        54\n",
      "\n",
      "    accuracy                           0.76       185\n",
      "   macro avg       0.71      0.72      0.72       185\n",
      "weighted avg       0.77      0.76      0.76       185\n",
      "\n",
      "[[107  24]\n",
      " [ 20  34]]\n",
      "Dokładność: 0.7621621621621621\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.84      0.82      0.83       131\n",
      "          OC       0.59      0.61      0.60        54\n",
      "\n",
      "    accuracy                           0.76       185\n",
      "   macro avg       0.71      0.72      0.72       185\n",
      "weighted avg       0.76      0.76      0.76       185\n",
      "\n",
      "[[108  23]\n",
      " [ 21  33]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\anaconda3\\envs\\poop\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# klasyfikacja z uzyciem sieci neuronowych\n",
    "\n",
    "def nn_classification(training_data, test_data):\n",
    "    # Oddziel etykiety od cech\n",
    "    X_train = training_data.drop('label', axis=1)\n",
    "    y_train = training_data['label']\n",
    "    X_test = test_data.drop('label', axis=1)\n",
    "    y_test = test_data['label']\n",
    "\n",
    "    # Normalizacja danych\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Klasyfikacja\n",
    "    nn = MLPClassifier(hidden_layer_sizes=(100,100), random_state=42)\n",
    "    nn.fit(X_train, y_train)\n",
    "    y_pred = nn.predict(X_test)\n",
    "\n",
    "    # Wypisanie dokładności i innych metryk\n",
    "    print(f\"Dokładność: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "nn_classification(training_data, test_data)\n",
    "nn_classification(training_data_synthetic, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "krzysiu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
