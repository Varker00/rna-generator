{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukasz\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import DBSCAN\n",
    "import umap\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               ENSG00000000419  ENSG00000000460  \\\n",
      "VUMC-HC-0033-TR2591                   3.635790         4.078496   \n",
      "Vumc-HD-70-TR1062                     4.546459         4.363044   \n",
      "VUMC-HC0053-DOT-HD-48h-TR3087         3.861049         4.079708   \n",
      "Vumc-HD-149-TR932                     4.727528         3.937986   \n",
      "Vumc-HD-36-TR1165                     4.402386         3.862107   \n",
      "...                                        ...              ...   \n",
      "TR3544-OVA-LUMC                       4.745738         4.289456   \n",
      "TR4341-OVA-LUMC                       4.092927         4.020636   \n",
      "Cath-Ova-CZE-022-TR2770               3.083092         4.274754   \n",
      "TR3947-OVA-CATH                       3.576816         3.930204   \n",
      "Cath-Ova-CZE-049-TR2731               3.779636         4.717135   \n",
      "\n",
      "                               ENSG00000000938  ENSG00000001036  \\\n",
      "VUMC-HC-0033-TR2591                   4.432779         5.074815   \n",
      "Vumc-HD-70-TR1062                     5.786592         4.488737   \n",
      "VUMC-HC0053-DOT-HD-48h-TR3087         5.526849         5.057660   \n",
      "Vumc-HD-149-TR932                     4.923042         3.808559   \n",
      "Vumc-HD-36-TR1165                     6.484772         4.751692   \n",
      "...                                        ...              ...   \n",
      "TR3544-OVA-LUMC                       4.864629         4.077246   \n",
      "TR4341-OVA-LUMC                       3.083092         4.159671   \n",
      "Cath-Ova-CZE-022-TR2770               4.523804         4.274754   \n",
      "TR3947-OVA-CATH                       4.436232         4.512335   \n",
      "Cath-Ova-CZE-049-TR2731               5.174218         4.941277   \n",
      "\n",
      "                               ENSG00000001461  ENSG00000001497  \\\n",
      "VUMC-HC-0033-TR2591                   5.881595         3.535280   \n",
      "Vumc-HD-70-TR1062                     4.293956         4.884990   \n",
      "VUMC-HC0053-DOT-HD-48h-TR3087         4.798671         3.794667   \n",
      "Vumc-HD-149-TR932                     4.425196         3.410258   \n",
      "Vumc-HD-36-TR1165                     5.020424         4.402386   \n",
      "...                                        ...              ...   \n",
      "TR3544-OVA-LUMC                       4.864629         3.083092   \n",
      "TR4341-OVA-LUMC                       4.615997         3.630666   \n",
      "Cath-Ova-CZE-022-TR2770               3.083092         3.083092   \n",
      "TR3947-OVA-CATH                       4.713588         3.083092   \n",
      "Cath-Ova-CZE-049-TR2731               4.777210         3.932183   \n",
      "\n",
      "                               ENSG00000001629  ENSG00000001631  \\\n",
      "VUMC-HC-0033-TR2591                   4.796726         4.399111   \n",
      "Vumc-HD-70-TR1062                     3.951486         4.926369   \n",
      "VUMC-HC0053-DOT-HD-48h-TR3087         4.292393         3.636481   \n",
      "Vumc-HD-149-TR932                     4.389800         4.492627   \n",
      "Vumc-HD-36-TR1165                     5.596133         4.751692   \n",
      "...                                        ...              ...   \n",
      "TR3544-OVA-LUMC                       5.164942         4.864629   \n",
      "TR4341-OVA-LUMC                       5.029674         4.221862   \n",
      "Cath-Ova-CZE-022-TR2770               4.726388         3.083092   \n",
      "TR3947-OVA-CATH                       4.987423         4.436232   \n",
      "Cath-Ova-CZE-049-TR2731               4.653811         4.653811   \n",
      "\n",
      "                               ENSG00000002330  ENSG00000002549  ...  \\\n",
      "VUMC-HC-0033-TR2591                   4.820505         4.954165  ...   \n",
      "Vumc-HD-70-TR1062                     4.139052         6.072522  ...   \n",
      "VUMC-HC0053-DOT-HD-48h-TR3087         4.617108         4.724280  ...   \n",
      "Vumc-HD-149-TR932                     4.556107         4.945413  ...   \n",
      "Vumc-HD-36-TR1165                     4.402386         4.751692  ...   \n",
      "...                                        ...              ...  ...   \n",
      "TR3544-OVA-LUMC                       5.548680         5.332012  ...   \n",
      "TR4341-OVA-LUMC                       5.114528         4.615997  ...   \n",
      "Cath-Ova-CZE-022-TR2770               4.899023         4.274754  ...   \n",
      "TR3947-OVA-CATH                       4.987423         4.650377  ...   \n",
      "Cath-Ova-CZE-049-TR2731               4.889004         5.216115  ...   \n",
      "\n",
      "                               ENSG00000257923  ENSG00000258890  \\\n",
      "VUMC-HC-0033-TR2591                   8.643616         4.211676   \n",
      "Vumc-HD-70-TR1062                     7.905229         4.601320   \n",
      "VUMC-HC0053-DOT-HD-48h-TR3087         8.012204         3.861049   \n",
      "Vumc-HD-149-TR932                     7.365315         3.083092   \n",
      "Vumc-HD-36-TR1165                     7.653843         5.339481   \n",
      "...                                        ...              ...   \n",
      "TR3544-OVA-LUMC                       7.506947         5.846969   \n",
      "TR4341-OVA-LUMC                       8.308118         4.969762   \n",
      "Cath-Ova-CZE-022-TR2770               7.239078         3.937349   \n",
      "TR3947-OVA-CATH                       7.686619         4.265041   \n",
      "Cath-Ova-CZE-049-TR2731               8.597493         4.169315   \n",
      "\n",
      "                               ENSG00000263563  ENSG00000264538  \\\n",
      "VUMC-HC-0033-TR2591                   4.211676         4.078496   \n",
      "Vumc-HD-70-TR1062                     4.293956         4.546459   \n",
      "VUMC-HC0053-DOT-HD-48h-TR3087         4.724280         4.253528   \n",
      "Vumc-HD-149-TR932                     4.389800         4.524826   \n",
      "Vumc-HD-36-TR1165                     4.172174         5.515912   \n",
      "...                                        ...              ...   \n",
      "TR3544-OVA-LUMC                       5.735327         4.289456   \n",
      "TR4341-OVA-LUMC                       4.656541         4.874104   \n",
      "Cath-Ova-CZE-022-TR2770               4.899023         3.937349   \n",
      "TR3947-OVA-CATH                       4.354229         4.830649   \n",
      "Cath-Ova-CZE-049-TR2731               4.169315         4.653811   \n",
      "\n",
      "                               ENSG00000266356  ENSG00000266714  \\\n",
      "VUMC-HC-0033-TR2591                   5.286517         4.465409   \n",
      "Vumc-HD-70-TR1062                     5.339434         4.139052   \n",
      "VUMC-HC0053-DOT-HD-48h-TR3087         5.305058         4.030369   \n",
      "Vumc-HD-149-TR932                     5.746547         3.808559   \n",
      "Vumc-HD-36-TR1165                     4.172174         6.355612   \n",
      "...                                        ...              ...   \n",
      "TR3544-OVA-LUMC                       4.972928         4.613500   \n",
      "TR4341-OVA-LUMC                       5.628587         4.733592   \n",
      "Cath-Ova-CZE-022-TR2770               4.899023         3.083092   \n",
      "TR3947-OVA-CATH                       5.081946         4.583478   \n",
      "Cath-Ova-CZE-049-TR2731               5.086103         3.779636   \n",
      "\n",
      "                               ENSG00000269028  ENSG00000271043  \\\n",
      "VUMC-HC-0033-TR2591                   7.757440         6.525607   \n",
      "Vumc-HD-70-TR1062                     6.645036         5.397116   \n",
      "VUMC-HC0053-DOT-HD-48h-TR3087         4.253528         3.720811   \n",
      "Vumc-HD-149-TR932                     8.517492         6.826289   \n",
      "Vumc-HD-36-TR1165                     7.025844         5.339481   \n",
      "...                                        ...              ...   \n",
      "TR3544-OVA-LUMC                       4.613500         3.792876   \n",
      "TR4341-OVA-LUMC                       6.135236         5.141602   \n",
      "Cath-Ova-CZE-022-TR2770               7.831030         6.434225   \n",
      "TR3947-OVA-CATH                       5.169928         4.583478   \n",
      "Cath-Ova-CZE-049-TR2731               7.833584         6.550340   \n",
      "\n",
      "                               ENSG00000272168  Group  \n",
      "VUMC-HC-0033-TR2591                   4.911210      0  \n",
      "Vumc-HD-70-TR1062                     4.139052      0  \n",
      "VUMC-HC0053-DOT-HD-48h-TR3087         4.644850      0  \n",
      "Vumc-HD-149-TR932                     5.031082      0  \n",
      "Vumc-HD-36-TR1165                     5.339481      0  \n",
      "...                                        ...    ...  \n",
      "TR3544-OVA-LUMC                       5.735327      1  \n",
      "TR4341-OVA-LUMC                       4.437269      1  \n",
      "Cath-Ova-CZE-022-TR2770               4.726388      1  \n",
      "TR3947-OVA-CATH                       4.885162      1  \n",
      "Cath-Ova-CZE-049-TR2731               5.334292      1  \n",
      "\n",
      "[278 rows x 5347 columns]\n",
      "                     ENSG00000000419  ENSG00000000460  ENSG00000000938  \\\n",
      "Vumc-HD-101-TR922           3.632451         3.775522         4.260973   \n",
      "Vumc-HD-103-TR923           5.424969         3.995549         7.067806   \n",
      "Vumc-HD-130-TR926           5.966390         3.931296         6.253597   \n",
      "Vumc-HD-145-TR930           4.139867         3.648963         4.167549   \n",
      "Vumc-HD-155-TR934           4.630723         4.043891         5.573233   \n",
      "...                              ...              ...              ...   \n",
      "MGH-OVARY-34-TR1265         3.978218         4.663488         4.589160   \n",
      "MGH-OVARY-37-TR1266         4.397115         3.819915         5.444120   \n",
      "MGH-OVARY-38-TR1367         4.827984         4.290696         4.957315   \n",
      "MGH-OVARY-40-TR1260         4.148487         3.648578         5.095472   \n",
      "MGH-OVARY-43-TR1263         3.083092         4.503958         4.726977   \n",
      "\n",
      "                     ENSG00000001036  ENSG00000001461  ENSG00000001497  \\\n",
      "Vumc-HD-101-TR922           4.543570         5.029391         3.855448   \n",
      "Vumc-HD-103-TR923           4.941661         4.259827         4.829900   \n",
      "Vumc-HD-130-TR926           4.745940         4.514088         4.114825   \n",
      "Vumc-HD-145-TR930           4.914034         4.768445         3.916181   \n",
      "Vumc-HD-155-TR934           4.494151         4.249651         4.418887   \n",
      "...                              ...              ...              ...   \n",
      "MGH-OVARY-34-TR1265         5.005191         4.423701         3.083092   \n",
      "MGH-OVARY-37-TR1266         4.760171         4.618651         4.072150   \n",
      "MGH-OVARY-38-TR1367         4.974731         4.154661         3.732795   \n",
      "MGH-OVARY-40-TR1260         4.589520         3.939784         3.083092   \n",
      "MGH-OVARY-43-TR1263         4.222493         3.603173         3.898958   \n",
      "\n",
      "                     ENSG00000001629  ENSG00000001631  ENSG00000002330  \\\n",
      "Vumc-HD-101-TR922           4.628870         4.349890         4.753364   \n",
      "Vumc-HD-103-TR923           4.353655         5.597112         4.849252   \n",
      "Vumc-HD-130-TR926           4.476669         5.332266         5.061243   \n",
      "Vumc-HD-145-TR930           4.139867         4.019530         4.900234   \n",
      "Vumc-HD-155-TR934           5.186832         5.102487         5.012171   \n",
      "...                              ...              ...              ...   \n",
      "MGH-OVARY-34-TR1265         5.273127         4.423701         4.589160   \n",
      "MGH-OVARY-37-TR1266         4.964085         4.925933         4.427425   \n",
      "MGH-OVARY-38-TR1367         4.591402         4.225111         4.726330   \n",
      "MGH-OVARY-40-TR1260         4.148487         3.410963         4.703847   \n",
      "MGH-OVARY-43-TR1263         4.325214         4.275201         4.620937   \n",
      "\n",
      "                     ENSG00000002549  ...  ENSG00000257923  ENSG00000258890  \\\n",
      "Vumc-HD-101-TR922           4.969059  ...         8.159009         4.023624   \n",
      "Vumc-HD-103-TR923           5.680688  ...         6.521378         5.553313   \n",
      "Vumc-HD-130-TR926           6.133154  ...         5.893660         5.603847   \n",
      "Vumc-HD-145-TR930           4.799002  ...         7.619884         3.750960   \n",
      "Vumc-HD-155-TR934           4.152600  ...         5.445328         4.964464   \n",
      "...                              ...  ...              ...              ...   \n",
      "MGH-OVARY-34-TR1265         5.294945  ...         8.191514         4.111445   \n",
      "MGH-OVARY-37-TR1266         5.482468  ...         8.128540         5.037059   \n",
      "MGH-OVARY-38-TR1367         5.875866  ...         6.209606         4.591402   \n",
      "MGH-OVARY-40-TR1260         4.676313  ...         7.133363         4.807953   \n",
      "MGH-OVARY-43-TR1263         5.024796  ...         7.693268         4.043519   \n",
      "\n",
      "                     ENSG00000263563  ENSG00000264538  ENSG00000266356  \\\n",
      "Vumc-HD-101-TR922           4.677134         4.677134         5.086967   \n",
      "Vumc-HD-103-TR923           4.769902         4.292098         5.387720   \n",
      "Vumc-HD-130-TR926           4.913675         4.312167         5.508326   \n",
      "Vumc-HD-145-TR930           4.341490         4.019530         5.708351   \n",
      "Vumc-HD-155-TR934           4.752649         4.337809         5.897569   \n",
      "...                              ...              ...              ...   \n",
      "MGH-OVARY-34-TR1265         4.698922         5.358311         4.830855   \n",
      "MGH-OVARY-37-TR1266         4.072150         4.593273         5.444120   \n",
      "MGH-OVARY-38-TR1367         5.008851         4.410180         5.775851   \n",
      "MGH-OVARY-40-TR1260         4.856791         4.462215         4.832619   \n",
      "MGH-OVARY-43-TR1263         4.620937         4.166685         5.126451   \n",
      "\n",
      "                     ENSG00000266714  ENSG00000269028  ENSG00000271043  \\\n",
      "Vumc-HD-101-TR922           3.684170         7.911457         6.687347   \n",
      "Vumc-HD-103-TR923           5.869712         7.238790         5.963607   \n",
      "Vumc-HD-130-TR926           4.266525         8.425523         6.674708   \n",
      "Vumc-HD-145-TR930           4.081793         7.590476         6.033518   \n",
      "Vumc-HD-155-TR934           4.249651         8.373381         7.161702   \n",
      "...                              ...              ...              ...   \n",
      "MGH-OVARY-34-TR1265         4.111445         5.457626         4.799217   \n",
      "MGH-OVARY-37-TR1266         4.154688         5.377654         4.667769   \n",
      "MGH-OVARY-38-TR1367         3.588032         7.611499         5.737602   \n",
      "MGH-OVARY-40-TR1260         4.970970         8.255088         6.721114   \n",
      "MGH-OVARY-43-TR1263         4.043519         8.525689         7.009326   \n",
      "\n",
      "                     ENSG00000272168  Group  \n",
      "Vumc-HD-101-TR922           4.753364      0  \n",
      "Vumc-HD-103-TR923           4.353655      0  \n",
      "Vumc-HD-130-TR926           5.588388      0  \n",
      "Vumc-HD-145-TR930           5.647128      0  \n",
      "Vumc-HD-155-TR934           5.376487      0  \n",
      "...                              ...    ...  \n",
      "MGH-OVARY-34-TR1265         5.316407      1  \n",
      "MGH-OVARY-37-TR1266         4.825023      1  \n",
      "MGH-OVARY-38-TR1367         4.037426      1  \n",
      "MGH-OVARY-40-TR1260         4.619192      1  \n",
      "MGH-OVARY-43-TR1263         4.372855      1  \n",
      "\n",
      "[185 rows x 5347 columns]\n"
     ]
    }
   ],
   "source": [
    "training_data = pd.read_csv('../classifier_data/HC_OC_training.csv', sep='\\t', index_col=0)\n",
    "\n",
    "\n",
    "print(training_data)\n",
    "\n",
    "test_data = pd.read_csv('../classifier_data/HC_OC_test.csv', sep='\\t', index_col=0)\n",
    "\n",
    "\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the columns that are in both datasets\n",
    "# Znalezienie wspólnych kolumn\n",
    "common_columns = training_data.columns.intersection(test_data.columns)\n",
    "\n",
    "# Uporządkowanie kolumn w real_data\n",
    "training_data = training_data[common_columns]\n",
    "\n",
    "# Uporządkowanie kolumn w synthetic_data\n",
    "test_data = test_data[common_columns]\n",
    "# synthetic_data = real_data\n",
    "# # # # add noise to synthetic data\n",
    "# synthetic_data = synthetic_data + np.random.normal(0, 0.001, synthetic_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <th>ENSG00000000938</th>\n",
       "      <th>ENSG00000001036</th>\n",
       "      <th>ENSG00000001461</th>\n",
       "      <th>ENSG00000001497</th>\n",
       "      <th>ENSG00000001629</th>\n",
       "      <th>ENSG00000001631</th>\n",
       "      <th>ENSG00000002330</th>\n",
       "      <th>ENSG00000002549</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000257923</th>\n",
       "      <th>ENSG00000258890</th>\n",
       "      <th>ENSG00000263563</th>\n",
       "      <th>ENSG00000264538</th>\n",
       "      <th>ENSG00000266356</th>\n",
       "      <th>ENSG00000266714</th>\n",
       "      <th>ENSG00000269028</th>\n",
       "      <th>ENSG00000271043</th>\n",
       "      <th>ENSG00000272168</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>278.000000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.312911</td>\n",
       "      <td>4.110307</td>\n",
       "      <td>5.515457</td>\n",
       "      <td>4.703468</td>\n",
       "      <td>4.535794</td>\n",
       "      <td>4.039753</td>\n",
       "      <td>4.695119</td>\n",
       "      <td>4.583420</td>\n",
       "      <td>4.796150</td>\n",
       "      <td>5.159978</td>\n",
       "      <td>...</td>\n",
       "      <td>7.628701</td>\n",
       "      <td>4.409439</td>\n",
       "      <td>4.577222</td>\n",
       "      <td>4.483288</td>\n",
       "      <td>5.348049</td>\n",
       "      <td>4.459864</td>\n",
       "      <td>6.200487</td>\n",
       "      <td>5.199333</td>\n",
       "      <td>4.728090</td>\n",
       "      <td>0.291367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.805121</td>\n",
       "      <td>0.578530</td>\n",
       "      <td>1.247236</td>\n",
       "      <td>0.522821</td>\n",
       "      <td>0.661682</td>\n",
       "      <td>0.727049</td>\n",
       "      <td>0.558479</td>\n",
       "      <td>0.669908</td>\n",
       "      <td>0.368203</td>\n",
       "      <td>0.909917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692858</td>\n",
       "      <td>0.861622</td>\n",
       "      <td>0.349168</td>\n",
       "      <td>0.561457</td>\n",
       "      <td>0.591832</td>\n",
       "      <td>1.117826</td>\n",
       "      <td>1.506739</td>\n",
       "      <td>1.177985</td>\n",
       "      <td>0.555509</td>\n",
       "      <td>0.455212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>...</td>\n",
       "      <td>5.105966</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.802979</td>\n",
       "      <td>3.762311</td>\n",
       "      <td>4.696203</td>\n",
       "      <td>4.481264</td>\n",
       "      <td>4.144286</td>\n",
       "      <td>3.506609</td>\n",
       "      <td>4.307304</td>\n",
       "      <td>4.248171</td>\n",
       "      <td>4.584386</td>\n",
       "      <td>4.701116</td>\n",
       "      <td>...</td>\n",
       "      <td>7.308699</td>\n",
       "      <td>3.869720</td>\n",
       "      <td>4.395317</td>\n",
       "      <td>4.167531</td>\n",
       "      <td>4.998070</td>\n",
       "      <td>3.571123</td>\n",
       "      <td>5.030074</td>\n",
       "      <td>4.313747</td>\n",
       "      <td>4.436789</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.251197</td>\n",
       "      <td>4.136669</td>\n",
       "      <td>5.305620</td>\n",
       "      <td>4.705545</td>\n",
       "      <td>4.600594</td>\n",
       "      <td>4.036580</td>\n",
       "      <td>4.699560</td>\n",
       "      <td>4.561179</td>\n",
       "      <td>4.793947</td>\n",
       "      <td>5.082831</td>\n",
       "      <td>...</td>\n",
       "      <td>7.710763</td>\n",
       "      <td>4.345390</td>\n",
       "      <td>4.572896</td>\n",
       "      <td>4.483368</td>\n",
       "      <td>5.375563</td>\n",
       "      <td>4.179792</td>\n",
       "      <td>6.253969</td>\n",
       "      <td>5.206753</td>\n",
       "      <td>4.734420</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.747670</td>\n",
       "      <td>4.472794</td>\n",
       "      <td>5.975199</td>\n",
       "      <td>4.986121</td>\n",
       "      <td>4.936263</td>\n",
       "      <td>4.497808</td>\n",
       "      <td>5.062279</td>\n",
       "      <td>4.977241</td>\n",
       "      <td>5.009427</td>\n",
       "      <td>5.572723</td>\n",
       "      <td>...</td>\n",
       "      <td>8.105805</td>\n",
       "      <td>4.882616</td>\n",
       "      <td>4.758044</td>\n",
       "      <td>4.817125</td>\n",
       "      <td>5.680205</td>\n",
       "      <td>5.377742</td>\n",
       "      <td>7.366203</td>\n",
       "      <td>6.003445</td>\n",
       "      <td>5.054724</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.767679</td>\n",
       "      <td>6.067968</td>\n",
       "      <td>9.793131</td>\n",
       "      <td>6.592116</td>\n",
       "      <td>6.372149</td>\n",
       "      <td>6.076003</td>\n",
       "      <td>6.545705</td>\n",
       "      <td>6.873423</td>\n",
       "      <td>6.065469</td>\n",
       "      <td>8.897936</td>\n",
       "      <td>...</td>\n",
       "      <td>8.954455</td>\n",
       "      <td>7.585211</td>\n",
       "      <td>6.557157</td>\n",
       "      <td>6.211780</td>\n",
       "      <td>7.131028</td>\n",
       "      <td>7.817975</td>\n",
       "      <td>11.225842</td>\n",
       "      <td>9.988463</td>\n",
       "      <td>6.606258</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 5347 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ENSG00000000419  ENSG00000000460  ENSG00000000938  ENSG00000001036  \\\n",
       "count       278.000000       278.000000       278.000000       278.000000   \n",
       "mean          4.312911         4.110307         5.515457         4.703468   \n",
       "std           0.805121         0.578530         1.247236         0.522821   \n",
       "min           3.083092         3.083092         3.083092         3.083092   \n",
       "25%           3.802979         3.762311         4.696203         4.481264   \n",
       "50%           4.251197         4.136669         5.305620         4.705545   \n",
       "75%           4.747670         4.472794         5.975199         4.986121   \n",
       "max           6.767679         6.067968         9.793131         6.592116   \n",
       "\n",
       "       ENSG00000001461  ENSG00000001497  ENSG00000001629  ENSG00000001631  \\\n",
       "count       278.000000       278.000000       278.000000       278.000000   \n",
       "mean          4.535794         4.039753         4.695119         4.583420   \n",
       "std           0.661682         0.727049         0.558479         0.669908   \n",
       "min           3.083092         3.083092         3.083092         3.083092   \n",
       "25%           4.144286         3.506609         4.307304         4.248171   \n",
       "50%           4.600594         4.036580         4.699560         4.561179   \n",
       "75%           4.936263         4.497808         5.062279         4.977241   \n",
       "max           6.372149         6.076003         6.545705         6.873423   \n",
       "\n",
       "       ENSG00000002330  ENSG00000002549  ...  ENSG00000257923  \\\n",
       "count       278.000000       278.000000  ...       278.000000   \n",
       "mean          4.796150         5.159978  ...         7.628701   \n",
       "std           0.368203         0.909917  ...         0.692858   \n",
       "min           3.083092         3.083092  ...         5.105966   \n",
       "25%           4.584386         4.701116  ...         7.308699   \n",
       "50%           4.793947         5.082831  ...         7.710763   \n",
       "75%           5.009427         5.572723  ...         8.105805   \n",
       "max           6.065469         8.897936  ...         8.954455   \n",
       "\n",
       "       ENSG00000258890  ENSG00000263563  ENSG00000264538  ENSG00000266356  \\\n",
       "count       278.000000       278.000000       278.000000       278.000000   \n",
       "mean          4.409439         4.577222         4.483288         5.348049   \n",
       "std           0.861622         0.349168         0.561457         0.591832   \n",
       "min           3.083092         3.083092         3.083092         3.083092   \n",
       "25%           3.869720         4.395317         4.167531         4.998070   \n",
       "50%           4.345390         4.572896         4.483368         5.375563   \n",
       "75%           4.882616         4.758044         4.817125         5.680205   \n",
       "max           7.585211         6.557157         6.211780         7.131028   \n",
       "\n",
       "       ENSG00000266714  ENSG00000269028  ENSG00000271043  ENSG00000272168  \\\n",
       "count       278.000000       278.000000       278.000000       278.000000   \n",
       "mean          4.459864         6.200487         5.199333         4.728090   \n",
       "std           1.117826         1.506739         1.177985         0.555509   \n",
       "min           3.083092         3.083092         3.083092         3.083092   \n",
       "25%           3.571123         5.030074         4.313747         4.436789   \n",
       "50%           4.179792         6.253969         5.206753         4.734420   \n",
       "75%           5.377742         7.366203         6.003445         5.054724   \n",
       "max           7.817975        11.225842         9.988463         6.606258   \n",
       "\n",
       "            Group  \n",
       "count  278.000000  \n",
       "mean     0.291367  \n",
       "std      0.455212  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      0.000000  \n",
       "75%      1.000000  \n",
       "max      1.000000  \n",
       "\n",
       "[8 rows x 5347 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <th>ENSG00000000938</th>\n",
       "      <th>ENSG00000001036</th>\n",
       "      <th>ENSG00000001461</th>\n",
       "      <th>ENSG00000001497</th>\n",
       "      <th>ENSG00000001629</th>\n",
       "      <th>ENSG00000001631</th>\n",
       "      <th>ENSG00000002330</th>\n",
       "      <th>ENSG00000002549</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000257923</th>\n",
       "      <th>ENSG00000258890</th>\n",
       "      <th>ENSG00000263563</th>\n",
       "      <th>ENSG00000264538</th>\n",
       "      <th>ENSG00000266356</th>\n",
       "      <th>ENSG00000266714</th>\n",
       "      <th>ENSG00000269028</th>\n",
       "      <th>ENSG00000271043</th>\n",
       "      <th>ENSG00000272168</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.279268</td>\n",
       "      <td>4.120439</td>\n",
       "      <td>5.407516</td>\n",
       "      <td>4.739876</td>\n",
       "      <td>4.582939</td>\n",
       "      <td>3.986007</td>\n",
       "      <td>4.606486</td>\n",
       "      <td>4.573577</td>\n",
       "      <td>4.779196</td>\n",
       "      <td>5.151998</td>\n",
       "      <td>...</td>\n",
       "      <td>7.711113</td>\n",
       "      <td>4.373899</td>\n",
       "      <td>4.555756</td>\n",
       "      <td>4.432652</td>\n",
       "      <td>5.390868</td>\n",
       "      <td>4.350106</td>\n",
       "      <td>6.060914</td>\n",
       "      <td>5.100829</td>\n",
       "      <td>4.738100</td>\n",
       "      <td>0.291892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.721486</td>\n",
       "      <td>0.515487</td>\n",
       "      <td>1.092092</td>\n",
       "      <td>0.470632</td>\n",
       "      <td>0.592127</td>\n",
       "      <td>0.682464</td>\n",
       "      <td>0.504905</td>\n",
       "      <td>0.667676</td>\n",
       "      <td>0.324951</td>\n",
       "      <td>0.771326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.676603</td>\n",
       "      <td>0.735602</td>\n",
       "      <td>0.327084</td>\n",
       "      <td>0.520330</td>\n",
       "      <td>0.442905</td>\n",
       "      <td>0.980247</td>\n",
       "      <td>1.561162</td>\n",
       "      <td>1.192287</td>\n",
       "      <td>0.537480</td>\n",
       "      <td>0.455867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>...</td>\n",
       "      <td>5.445328</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>4.388405</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>3.083092</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.811984</td>\n",
       "      <td>3.823520</td>\n",
       "      <td>4.645284</td>\n",
       "      <td>4.529107</td>\n",
       "      <td>4.254529</td>\n",
       "      <td>3.456565</td>\n",
       "      <td>4.320739</td>\n",
       "      <td>4.242960</td>\n",
       "      <td>4.603469</td>\n",
       "      <td>4.718681</td>\n",
       "      <td>...</td>\n",
       "      <td>7.392252</td>\n",
       "      <td>3.950087</td>\n",
       "      <td>4.379889</td>\n",
       "      <td>4.090836</td>\n",
       "      <td>5.059676</td>\n",
       "      <td>3.618149</td>\n",
       "      <td>4.783300</td>\n",
       "      <td>4.274964</td>\n",
       "      <td>4.453360</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.187932</td>\n",
       "      <td>4.129796</td>\n",
       "      <td>5.259546</td>\n",
       "      <td>4.804204</td>\n",
       "      <td>4.647815</td>\n",
       "      <td>4.049833</td>\n",
       "      <td>4.597338</td>\n",
       "      <td>4.594354</td>\n",
       "      <td>4.772618</td>\n",
       "      <td>5.059780</td>\n",
       "      <td>...</td>\n",
       "      <td>7.755541</td>\n",
       "      <td>4.292373</td>\n",
       "      <td>4.614126</td>\n",
       "      <td>4.413950</td>\n",
       "      <td>5.371258</td>\n",
       "      <td>4.081793</td>\n",
       "      <td>5.955549</td>\n",
       "      <td>4.959521</td>\n",
       "      <td>4.765672</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.736884</td>\n",
       "      <td>4.439268</td>\n",
       "      <td>6.027215</td>\n",
       "      <td>5.033146</td>\n",
       "      <td>4.942248</td>\n",
       "      <td>4.367981</td>\n",
       "      <td>4.935051</td>\n",
       "      <td>4.998213</td>\n",
       "      <td>4.984027</td>\n",
       "      <td>5.639733</td>\n",
       "      <td>...</td>\n",
       "      <td>8.162565</td>\n",
       "      <td>4.807953</td>\n",
       "      <td>4.749269</td>\n",
       "      <td>4.728381</td>\n",
       "      <td>5.684068</td>\n",
       "      <td>5.013587</td>\n",
       "      <td>7.306161</td>\n",
       "      <td>5.920427</td>\n",
       "      <td>5.028659</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.206412</td>\n",
       "      <td>5.417481</td>\n",
       "      <td>8.477129</td>\n",
       "      <td>5.696946</td>\n",
       "      <td>6.031846</td>\n",
       "      <td>6.363055</td>\n",
       "      <td>5.831794</td>\n",
       "      <td>6.546365</td>\n",
       "      <td>5.639733</td>\n",
       "      <td>7.268793</td>\n",
       "      <td>...</td>\n",
       "      <td>9.436642</td>\n",
       "      <td>6.827322</td>\n",
       "      <td>5.239932</td>\n",
       "      <td>6.250128</td>\n",
       "      <td>6.736777</td>\n",
       "      <td>6.989681</td>\n",
       "      <td>10.265634</td>\n",
       "      <td>9.488314</td>\n",
       "      <td>6.526054</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 5347 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ENSG00000000419  ENSG00000000460  ENSG00000000938  ENSG00000001036  \\\n",
       "count       185.000000       185.000000       185.000000       185.000000   \n",
       "mean          4.279268         4.120439         5.407516         4.739876   \n",
       "std           0.721486         0.515487         1.092092         0.470632   \n",
       "min           3.083092         3.083092         3.083092         3.083092   \n",
       "25%           3.811984         3.823520         4.645284         4.529107   \n",
       "50%           4.187932         4.129796         5.259546         4.804204   \n",
       "75%           4.736884         4.439268         6.027215         5.033146   \n",
       "max           6.206412         5.417481         8.477129         5.696946   \n",
       "\n",
       "       ENSG00000001461  ENSG00000001497  ENSG00000001629  ENSG00000001631  \\\n",
       "count       185.000000       185.000000       185.000000       185.000000   \n",
       "mean          4.582939         3.986007         4.606486         4.573577   \n",
       "std           0.592127         0.682464         0.504905         0.667676   \n",
       "min           3.083092         3.083092         3.083092         3.083092   \n",
       "25%           4.254529         3.456565         4.320739         4.242960   \n",
       "50%           4.647815         4.049833         4.597338         4.594354   \n",
       "75%           4.942248         4.367981         4.935051         4.998213   \n",
       "max           6.031846         6.363055         5.831794         6.546365   \n",
       "\n",
       "       ENSG00000002330  ENSG00000002549  ...  ENSG00000257923  \\\n",
       "count       185.000000       185.000000  ...       185.000000   \n",
       "mean          4.779196         5.151998  ...         7.711113   \n",
       "std           0.324951         0.771326  ...         0.676603   \n",
       "min           3.083092         3.083092  ...         5.445328   \n",
       "25%           4.603469         4.718681  ...         7.392252   \n",
       "50%           4.772618         5.059780  ...         7.755541   \n",
       "75%           4.984027         5.639733  ...         8.162565   \n",
       "max           5.639733         7.268793  ...         9.436642   \n",
       "\n",
       "       ENSG00000258890  ENSG00000263563  ENSG00000264538  ENSG00000266356  \\\n",
       "count       185.000000       185.000000       185.000000       185.000000   \n",
       "mean          4.373899         4.555756         4.432652         5.390868   \n",
       "std           0.735602         0.327084         0.520330         0.442905   \n",
       "min           3.083092         3.083092         3.083092         4.388405   \n",
       "25%           3.950087         4.379889         4.090836         5.059676   \n",
       "50%           4.292373         4.614126         4.413950         5.371258   \n",
       "75%           4.807953         4.749269         4.728381         5.684068   \n",
       "max           6.827322         5.239932         6.250128         6.736777   \n",
       "\n",
       "       ENSG00000266714  ENSG00000269028  ENSG00000271043  ENSG00000272168  \\\n",
       "count       185.000000       185.000000       185.000000       185.000000   \n",
       "mean          4.350106         6.060914         5.100829         4.738100   \n",
       "std           0.980247         1.561162         1.192287         0.537480   \n",
       "min           3.083092         3.083092         3.083092         3.083092   \n",
       "25%           3.618149         4.783300         4.274964         4.453360   \n",
       "50%           4.081793         5.955549         4.959521         4.765672   \n",
       "75%           5.013587         7.306161         5.920427         5.028659   \n",
       "max           6.989681        10.265634         9.488314         6.526054   \n",
       "\n",
       "            Group  \n",
       "count  185.000000  \n",
       "mean     0.291892  \n",
       "std      0.455867  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      0.000000  \n",
       "75%      1.000000  \n",
       "max      1.000000  \n",
       "\n",
       "[8 rows x 5347 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wykorzystanie klasyfikatorów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność: 0.543010752688172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      0.37      0.41        78\n",
      "         1.0       0.60      0.67      0.63       108\n",
      "\n",
      "    accuracy                           0.54       186\n",
      "   macro avg       0.52      0.52      0.52       186\n",
      "weighted avg       0.53      0.54      0.54       186\n",
      "\n",
      "[[29 49]\n",
      " [36 72]]\n"
     ]
    }
   ],
   "source": [
    "# klasyfikacja z uyciem svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def svm_classification(real_data, synthetic_data):\n",
    "    # Połączenie danych rzeczywistych i syntetycznych\n",
    "    combined_data = np.vstack((real_data, synthetic_data))\n",
    "\n",
    "    # Normalizacja danych\n",
    "    #scaler = StandardScaler()\n",
    "    #combined_data = scaler.fit_transform(combined_data)\n",
    "\n",
    "    # Stworzenie etykiet\n",
    "    labels = np.hstack((np.ones(len(real_data)), np.zeros(len(synthetic_data))))\n",
    "\n",
    "    # Podział na zbiór treningowy i testowy\n",
    "    X_train, X_test, y_train, y_test = train_test_split(combined_data, labels, test_size=0.4, random_state=42)\n",
    "\n",
    "    # Klasyfikacja przy użyciu SVM\n",
    "    svm = SVC(kernel='linear', random_state=42)\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred = svm.predict(X_test)\n",
    "\n",
    "    # Wypisanie dokładności i innych metryk\n",
    "    print(f\"Dokładność: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "svm_classification(training_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lukasz\\PycharmProjects\\git\\rna-generator\\data_analyses\\HC_OC_wtf_is_going_on.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lukasz/PycharmProjects/git/rna-generator/data_analyses/HC_OC_wtf_is_going_on.ipynb#X11sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mprint\u001b[39m(classification_report(y_test, y_pred))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lukasz/PycharmProjects/git/rna-generator/data_analyses/HC_OC_wtf_is_going_on.ipynb#X11sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mprint\u001b[39m(confusion_matrix(y_test, y_pred))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Lukasz/PycharmProjects/git/rna-generator/data_analyses/HC_OC_wtf_is_going_on.ipynb#X11sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m decision_tree_classification(training_data, test_data)\n",
      "\u001b[1;32mc:\\Users\\Lukasz\\PycharmProjects\\git\\rna-generator\\data_analyses\\HC_OC_wtf_is_going_on.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lukasz/PycharmProjects/git/rna-generator/data_analyses/HC_OC_wtf_is_going_on.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m scaler \u001b[39m=\u001b[39m StandardScaler()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lukasz/PycharmProjects/git/rna-generator/data_analyses/HC_OC_wtf_is_going_on.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m combined_data \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mfit_transform(combined_data)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Lukasz/PycharmProjects/git/rna-generator/data_analyses/HC_OC_wtf_is_going_on.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m labels \u001b[39m=\u001b[39m combined_data[\u001b[39m'\u001b[39;49m\u001b[39mGroup\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mvalues\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lukasz/PycharmProjects/git/rna-generator/data_analyses/HC_OC_wtf_is_going_on.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m combined_data\u001b[39m.\u001b[39mdrop(\u001b[39m'\u001b[39m\u001b[39mGroup\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lukasz/PycharmProjects/git/rna-generator/data_analyses/HC_OC_wtf_is_going_on.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(combined_data)\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# klasyfikacja z uyciem random forest\n",
    "def decision_tree_classification(real_data, synthetic_data):\n",
    "    # Połączenie danych rzeczywistych i syntetycznych\n",
    "    combined_data = np.vstack((real_data, synthetic_data))\n",
    "\n",
    "    # Normalizacja danych\n",
    "    scaler = StandardScaler()\n",
    "    combined_data = scaler.fit_transform(combined_data)\n",
    "\n",
    "    labels = combined_data['Group'].values\n",
    "    combined_data.drop('Group', axis=1)\n",
    "\n",
    "    print(combined_data)\n",
    "\n",
    "    # Stworzenie etykiet\n",
    "    # labels = np.hstack((np.ones(len(real_data)), np.zeros(len(synthetic_data))))\n",
    "\n",
    "    # Podział na zbiór treningowy i testowy\n",
    "    X_train, X_test, y_train, y_test = train_test_split(combined_data, labels, test_size=0.4, random_state=42)\n",
    "\n",
    "    # Klasyfikacja\n",
    "    dt = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "    dt.fit(X_train, y_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "\n",
    "    # Wypisanie dokładności i innych metryk\n",
    "    print(f\"Dokładność: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "decision_tree_classification(training_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność: 0.5698924731182796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.44      0.09      0.15        78\n",
      "         1.0       0.58      0.92      0.71       108\n",
      "\n",
      "    accuracy                           0.57       186\n",
      "   macro avg       0.51      0.50      0.43       186\n",
      "weighted avg       0.52      0.57      0.48       186\n",
      "\n",
      "[[ 7 71]\n",
      " [ 9 99]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# klasyfikacja z uyciem random forest\n",
    "def random_forest_classification(real_data, synthetic_data):\n",
    "    # Połączenie danych rzeczywistych i syntetycznych\n",
    "    combined_data = np.vstack((real_data, synthetic_data))\n",
    "\n",
    "    # Normalizacja danych\n",
    "    scaler = StandardScaler()\n",
    "    combined_data = scaler.fit_transform(combined_data)\n",
    "\n",
    "    # Stworzenie etykiet\n",
    "    labels = np.hstack((np.ones(len(real_data)), np.zeros(len(synthetic_data))))\n",
    "\n",
    "    # Podział na zbiór treningowy i testowy\n",
    "    X_train, X_test, y_train, y_test = train_test_split(combined_data, labels, test_size=0.4, random_state=42)\n",
    "\n",
    "    # Klasyfikacja\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # Wypisanie dokładności i innych metryk\n",
    "    print(f\"Dokładność: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "random_forest_classification(training_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność: 0.5591397849462365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      0.26      0.33        78\n",
      "         1.0       0.59      0.78      0.67       108\n",
      "\n",
      "    accuracy                           0.56       186\n",
      "   macro avg       0.52      0.52      0.50       186\n",
      "weighted avg       0.53      0.56      0.53       186\n",
      "\n",
      "[[20 58]\n",
      " [24 84]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# klasyfikacja z uyciem xgboost\n",
    "def xgboost_classification(real_data, synthetic_data):\n",
    "    # Połączenie danych rzeczywistych i syntetycznych\n",
    "    combined_data = np.vstack((real_data, synthetic_data))\n",
    "    \n",
    "    # Normalizacja danych\n",
    "    scaler = StandardScaler()\n",
    "    combined_data = scaler.fit_transform(combined_data)\n",
    "\n",
    "    # Stworzenie etykiet\n",
    "    labels = np.hstack((np.ones(len(real_data)), np.zeros(len(synthetic_data))))\n",
    "\n",
    "    # Podział na zbiór treningowy i testowy\n",
    "    X_train, X_test, y_train, y_test = train_test_split(combined_data, labels, test_size=0.4, random_state=42)\n",
    "\n",
    "    # Klasyfikacja\n",
    "    xgb = XGBClassifier(random_state=42)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred = xgb.predict(X_test)\n",
    "\n",
    "    # Wypisanie dokładności i innych metryk\n",
    "    print(f\"Dokładność: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "xgboost_classification(training_data, test_data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność: 0.5591397849462365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.36      0.41        78\n",
      "         1.0       0.60      0.70      0.65       108\n",
      "\n",
      "    accuracy                           0.56       186\n",
      "   macro avg       0.53      0.53      0.53       186\n",
      "weighted avg       0.55      0.56      0.55       186\n",
      "\n",
      "[[28 50]\n",
      " [32 76]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# klasyfikacja z uzyciem sieci neuronowych\n",
    "\n",
    "def nn_classification(real_data, synthetic_data):\n",
    "    # Połączenie danych rzeczywistych i syntetycznych\n",
    "    combined_data = np.vstack((real_data, synthetic_data))\n",
    "\n",
    "    # Normalizacja danych\n",
    "    scaler = StandardScaler()\n",
    "    combined_data = scaler.fit_transform(combined_data)\n",
    "\n",
    "    # Stworzenie etykiet\n",
    "    labels = np.hstack((np.ones(len(real_data)), np.zeros(len(synthetic_data))))\n",
    "\n",
    "    # Podział na zbiór treningowy i testowy\n",
    "    X_train, X_test, y_train, y_test = train_test_split(combined_data, labels, test_size=0.4, random_state=42)\n",
    "\n",
    "    # Klasyfikacja\n",
    "    nn = MLPClassifier(hidden_layer_sizes=(100,100), random_state=42)\n",
    "    nn.fit(X_train, y_train)\n",
    "    y_pred = nn.predict(X_test)\n",
    "\n",
    "    # Wypisanie dokładności i innych metryk\n",
    "    print(f\"Dokładność: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "nn_classification(training_data, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "krzysiu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
