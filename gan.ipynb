{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models, optimizers\n",
    "from keras.layers import Dense, LSTM, Embedding, LeakyReLU, BatchNormalization, Dropout, Input, ReLU\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57736, 69)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data_path = 'original_data/GSE158508_normalized_counts.tsv'\n",
    "data = pd.read_csv(data_path, sep='\\t', index_col=0)\n",
    "\n",
    "data_shape = data.shape[1]  # 69 columns\n",
    "\n",
    "# Save columns names for later use\n",
    "col_names = data.columns.values\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(latent_dim, data_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(64, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "    model.add(Dense(64, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    model.add(Dense(128))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "    model.add(Dense(2048))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "    model.add(Dense(4096))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    model.add(Dense(data_shape, activation='relu'))\n",
    "    \n",
    "    noise = Input(shape=(latent_dim,))\n",
    "    generated_data = model(noise)\n",
    "    \n",
    "    return Model(noise, generated_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(data_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(1024, input_dim=data_shape))\n",
    "    model.add(ReLU())\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Dense(1024))\n",
    "    model.add(ReLU())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(512))\n",
    "    model.add(ReLU())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(256))\n",
    "    model.add(ReLU())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(ReLU())\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    data = Input(shape=(data_shape,))\n",
    "    validity = model(data)\n",
    "    \n",
    "    return Model(data, validity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wymiary przestrzeni ukrytej\n",
    "latent_dim = 64\n",
    "\n",
    "# Budowa i kompilacja dyskryminatora\n",
    "discriminator = build_discriminator(data_shape)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "\n",
    "# Budowa generatora\n",
    "generator = build_generator(latent_dim, data_shape)\n",
    "\n",
    "# Generator bierze szum jako wejście i generuje dane\n",
    "z = Input(shape=(latent_dim,))\n",
    "generated_data = generator(z)\n",
    "\n",
    "# Tylko generator jest trenowany\n",
    "discriminator.trainable = False\n",
    "\n",
    "# Dyskryminator bierze wygenerowane dane jako wejście i określa ich prawdziwość\n",
    "validity = discriminator(generated_data)\n",
    "\n",
    "# Połączony model (stacked generator and discriminator)\n",
    "combined = Model(z, validity)\n",
    "combined.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_dir = './training_checkpoints'\n",
    "# checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "# checkpoint = tf.train.Checkpoint(generator=generator,\n",
    "#                                  discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_output(generated_data):\n",
    "    min_val = 0.873159932419581\n",
    "    return generated_data + min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, combined, data, latent_dim, epochs, batch_size=128, save_interval=50):\n",
    "    # Ładowanie i skalowanie danych\n",
    "    X_train = data.values\n",
    "\n",
    "    # Pętla po epokach\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        # ---------------------\n",
    "        #  Trenowanie dyskryminatora\n",
    "        # ---------------------\n",
    "\n",
    "        # Wybieranie losowych próbek\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        real_data = X_train[idx]\n",
    "\n",
    "        # Generowanie nowego szumu\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "\n",
    "        # Generowanie nowych danych\n",
    "        generated_data = generator.predict(noise)\n",
    "        generated_data = scale_output(generated_data)\n",
    "\n",
    "        # Trenowanie dyskryminatora\n",
    "        d_loss_real = discriminator.train_on_batch(real_data, np.ones((batch_size, 1)))\n",
    "        d_loss_fake = discriminator.train_on_batch(generated_data, np.zeros((batch_size, 1)))\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Trenowanie generatora\n",
    "        # ---------------------\n",
    "\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "\n",
    "        # Chcemy, aby dyskryminator uznał wygenerowane dane za prawdziwe\n",
    "        valid_y = np.array([1] * batch_size)\n",
    "\n",
    "        # Trenowanie generatora\n",
    "        g_loss = combined.train_on_batch(noise, valid_y)\n",
    "\n",
    "        # Zapisywanie postępów\n",
    "        if epoch % save_interval == 0:\n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "            print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "            #checkpoint.save(file_prefix = checkpoint_prefix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.838802, acc.: 30.47%] [G loss: 0.708507]\n",
      "Time for epoch 1 is 3.23549747467041 sec\n",
      "50 [D loss: 0.682237, acc.: 51.56%] [G loss: 0.979710]\n",
      "Time for epoch 51 is 0.17813944816589355 sec\n",
      "100 [D loss: 0.707888, acc.: 47.66%] [G loss: 0.749582]\n",
      "Time for epoch 101 is 0.1814873218536377 sec\n",
      "150 [D loss: 0.702724, acc.: 50.78%] [G loss: 0.708737]\n",
      "Time for epoch 151 is 0.17972993850708008 sec\n",
      "200 [D loss: 0.695175, acc.: 51.56%] [G loss: 0.701854]\n",
      "Time for epoch 201 is 0.17410039901733398 sec\n",
      "250 [D loss: 0.697000, acc.: 51.17%] [G loss: 0.694157]\n",
      "Time for epoch 251 is 0.17612695693969727 sec\n",
      "300 [D loss: 0.693497, acc.: 52.73%] [G loss: 0.699870]\n",
      "Time for epoch 301 is 0.26914119720458984 sec\n",
      "350 [D loss: 0.694649, acc.: 52.34%] [G loss: 0.691001]\n",
      "Time for epoch 351 is 0.2644312381744385 sec\n",
      "400 [D loss: 0.691035, acc.: 51.95%] [G loss: 0.694297]\n",
      "Time for epoch 401 is 0.32695579528808594 sec\n",
      "450 [D loss: 0.687431, acc.: 55.86%] [G loss: 0.694836]\n",
      "Time for epoch 451 is 0.295651912689209 sec\n",
      "500 [D loss: 0.698489, acc.: 51.56%] [G loss: 0.692192]\n",
      "Time for epoch 501 is 0.28971195220947266 sec\n",
      "550 [D loss: 0.691904, acc.: 51.56%] [G loss: 0.691142]\n",
      "Time for epoch 551 is 0.29472970962524414 sec\n",
      "600 [D loss: 0.693429, acc.: 49.61%] [G loss: 0.696717]\n",
      "Time for epoch 601 is 0.2844526767730713 sec\n",
      "650 [D loss: 0.693477, acc.: 48.83%] [G loss: 0.694490]\n",
      "Time for epoch 651 is 0.30568695068359375 sec\n",
      "700 [D loss: 0.695772, acc.: 47.27%] [G loss: 0.694647]\n",
      "Time for epoch 701 is 0.3079643249511719 sec\n",
      "750 [D loss: 0.687330, acc.: 49.22%] [G loss: 0.702235]\n",
      "Time for epoch 751 is 0.1829841136932373 sec\n",
      "800 [D loss: 0.691616, acc.: 48.05%] [G loss: 0.696365]\n",
      "Time for epoch 801 is 0.32802867889404297 sec\n",
      "850 [D loss: 0.695058, acc.: 44.14%] [G loss: 0.691026]\n",
      "Time for epoch 851 is 0.4026920795440674 sec\n",
      "900 [D loss: 0.694110, acc.: 49.22%] [G loss: 0.697009]\n",
      "Time for epoch 901 is 0.2997455596923828 sec\n",
      "950 [D loss: 0.690788, acc.: 45.31%] [G loss: 0.695196]\n",
      "Time for epoch 951 is 0.30725693702697754 sec\n",
      "1000 [D loss: 0.691727, acc.: 47.27%] [G loss: 0.697724]\n",
      "Time for epoch 1001 is 0.2980477809906006 sec\n",
      "1050 [D loss: 0.689487, acc.: 47.27%] [G loss: 0.704490]\n",
      "Time for epoch 1051 is 0.24994397163391113 sec\n",
      "1100 [D loss: 0.694536, acc.: 47.66%] [G loss: 0.711382]\n",
      "Time for epoch 1101 is 0.2565727233886719 sec\n",
      "1150 [D loss: 0.697511, acc.: 46.88%] [G loss: 0.703110]\n",
      "Time for epoch 1151 is 0.2567014694213867 sec\n",
      "1200 [D loss: 0.684503, acc.: 48.83%] [G loss: 0.705141]\n",
      "Time for epoch 1201 is 0.2796323299407959 sec\n",
      "1250 [D loss: 0.666758, acc.: 44.53%] [G loss: 0.719458]\n",
      "Time for epoch 1251 is 0.26479125022888184 sec\n",
      "1300 [D loss: 0.696188, acc.: 48.83%] [G loss: 0.693327]\n",
      "Time for epoch 1301 is 0.2991149425506592 sec\n",
      "1350 [D loss: 0.694781, acc.: 44.92%] [G loss: 0.693086]\n",
      "Time for epoch 1351 is 0.2332324981689453 sec\n",
      "1400 [D loss: 0.707143, acc.: 48.83%] [G loss: 0.687138]\n",
      "Time for epoch 1401 is 0.2042069435119629 sec\n",
      "1450 [D loss: 0.681844, acc.: 51.17%] [G loss: 0.690325]\n",
      "Time for epoch 1451 is 0.19769954681396484 sec\n",
      "1500 [D loss: 0.681615, acc.: 59.38%] [G loss: 0.699339]\n",
      "Time for epoch 1501 is 0.1915290355682373 sec\n",
      "1550 [D loss: 0.670527, acc.: 68.36%] [G loss: 0.719063]\n",
      "Time for epoch 1551 is 0.2145392894744873 sec\n",
      "1600 [D loss: 0.692666, acc.: 55.86%] [G loss: 0.827748]\n",
      "Time for epoch 1601 is 0.20066022872924805 sec\n",
      "1650 [D loss: 0.659725, acc.: 66.41%] [G loss: 0.746982]\n",
      "Time for epoch 1651 is 0.22069358825683594 sec\n",
      "1700 [D loss: 0.495164, acc.: 89.45%] [G loss: 1.481624]\n",
      "Time for epoch 1701 is 0.2674410343170166 sec\n",
      "1750 [D loss: 0.704422, acc.: 57.81%] [G loss: 1.166828]\n",
      "Time for epoch 1751 is 0.20490455627441406 sec\n",
      "1800 [D loss: 0.329611, acc.: 87.50%] [G loss: 1.246139]\n",
      "Time for epoch 1801 is 0.2125225067138672 sec\n",
      "1850 [D loss: 0.403479, acc.: 82.81%] [G loss: 1.683767]\n",
      "Time for epoch 1851 is 0.19094133377075195 sec\n",
      "1900 [D loss: 0.430915, acc.: 86.72%] [G loss: 1.289738]\n",
      "Time for epoch 1901 is 0.19540190696716309 sec\n",
      "1950 [D loss: 0.586456, acc.: 75.00%] [G loss: 1.401352]\n",
      "Time for epoch 1951 is 0.18323636054992676 sec\n",
      "2000 [D loss: 0.484039, acc.: 82.03%] [G loss: 1.869951]\n",
      "Time for epoch 2001 is 0.18661141395568848 sec\n",
      "2050 [D loss: 0.655716, acc.: 63.28%] [G loss: 2.181145]\n",
      "Time for epoch 2051 is 0.1989297866821289 sec\n",
      "2100 [D loss: 0.510316, acc.: 85.94%] [G loss: 1.359494]\n",
      "Time for epoch 2101 is 0.18811655044555664 sec\n",
      "2150 [D loss: 0.694911, acc.: 50.00%] [G loss: 1.009205]\n",
      "Time for epoch 2151 is 0.2225344181060791 sec\n",
      "2200 [D loss: 0.647044, acc.: 66.80%] [G loss: 0.953721]\n",
      "Time for epoch 2201 is 0.1827247142791748 sec\n",
      "2250 [D loss: 0.636701, acc.: 74.22%] [G loss: 0.950836]\n",
      "Time for epoch 2251 is 0.18200421333312988 sec\n",
      "2300 [D loss: 0.702275, acc.: 48.05%] [G loss: 0.898802]\n",
      "Time for epoch 2301 is 0.17440080642700195 sec\n",
      "2350 [D loss: 0.651797, acc.: 58.20%] [G loss: 0.858172]\n",
      "Time for epoch 2351 is 0.1747739315032959 sec\n",
      "2400 [D loss: 0.707335, acc.: 55.86%] [G loss: 0.908816]\n",
      "Time for epoch 2401 is 0.17409491539001465 sec\n",
      "2450 [D loss: 0.692745, acc.: 52.34%] [G loss: 0.770581]\n",
      "Time for epoch 2451 is 0.3355693817138672 sec\n",
      "2500 [D loss: 0.684936, acc.: 57.42%] [G loss: 0.723032]\n",
      "Time for epoch 2501 is 0.2066507339477539 sec\n",
      "2550 [D loss: 0.691152, acc.: 51.95%] [G loss: 0.749703]\n",
      "Time for epoch 2551 is 0.17963862419128418 sec\n",
      "2600 [D loss: 0.692973, acc.: 48.44%] [G loss: 0.753374]\n",
      "Time for epoch 2601 is 0.17083477973937988 sec\n",
      "2650 [D loss: 0.680957, acc.: 51.56%] [G loss: 0.720753]\n",
      "Time for epoch 2651 is 0.17542648315429688 sec\n",
      "2700 [D loss: 0.706053, acc.: 49.22%] [G loss: 0.731456]\n",
      "Time for epoch 2701 is 0.17533278465270996 sec\n",
      "2750 [D loss: 0.710966, acc.: 42.97%] [G loss: 0.614301]\n",
      "Time for epoch 2751 is 0.16756343841552734 sec\n",
      "2800 [D loss: 0.699479, acc.: 50.39%] [G loss: 0.639180]\n",
      "Time for epoch 2801 is 0.16710901260375977 sec\n",
      "2850 [D loss: 0.685123, acc.: 55.08%] [G loss: 0.634243]\n",
      "Time for epoch 2851 is 0.17112374305725098 sec\n",
      "2900 [D loss: 0.686443, acc.: 59.77%] [G loss: 0.632144]\n",
      "Time for epoch 2901 is 0.18226218223571777 sec\n",
      "2950 [D loss: 0.677284, acc.: 58.98%] [G loss: 0.651178]\n",
      "Time for epoch 2951 is 0.17442703247070312 sec\n"
     ]
    }
   ],
   "source": [
    "# Trenowanie modelu\n",
    "train(generator, discriminator, combined, data, latent_dim, epochs=3000, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate after the final epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(generator, n_samples):\n",
    "    noise = np.random.normal(0, 1, size=(n_samples, latent_dim))\n",
    "    generated_data = generator.predict(noise)\n",
    "    generated_data = scale_output(generated_data)\n",
    "    return generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data = generate_data(generator, n_samples=57736)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the generated data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(synthetic_data)\n",
    "# append column names to the data \n",
    "df.columns = col_names\n",
    "df.to_csv('synthetic_data/generated_data.tsv', sep='\\t', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TR4190</th>\n",
       "      <th>TR4184</th>\n",
       "      <th>TR4193</th>\n",
       "      <th>TR4186</th>\n",
       "      <th>TR4185</th>\n",
       "      <th>TR4219</th>\n",
       "      <th>TR4268</th>\n",
       "      <th>TR4269</th>\n",
       "      <th>TR4271</th>\n",
       "      <th>TR4273</th>\n",
       "      <th>...</th>\n",
       "      <th>TR4191</th>\n",
       "      <th>TR4017</th>\n",
       "      <th>TR4329</th>\n",
       "      <th>TR4215</th>\n",
       "      <th>TR4189</th>\n",
       "      <th>TR4011</th>\n",
       "      <th>TR4044</th>\n",
       "      <th>TR4267</th>\n",
       "      <th>TR4149</th>\n",
       "      <th>TR4188</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.194206</td>\n",
       "      <td>1.338851</td>\n",
       "      <td>1.171084</td>\n",
       "      <td>1.233508</td>\n",
       "      <td>1.238979</td>\n",
       "      <td>1.281862</td>\n",
       "      <td>1.404603</td>\n",
       "      <td>1.240871</td>\n",
       "      <td>1.188165</td>\n",
       "      <td>1.385383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.175039</td>\n",
       "      <td>1.339240</td>\n",
       "      <td>1.198407</td>\n",
       "      <td>1.205923</td>\n",
       "      <td>1.196342</td>\n",
       "      <td>1.547039</td>\n",
       "      <td>1.202872</td>\n",
       "      <td>1.283150</td>\n",
       "      <td>1.265179</td>\n",
       "      <td>1.345267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.145634</td>\n",
       "      <td>1.292237</td>\n",
       "      <td>1.097246</td>\n",
       "      <td>1.157664</td>\n",
       "      <td>1.184453</td>\n",
       "      <td>1.203927</td>\n",
       "      <td>1.447374</td>\n",
       "      <td>1.170842</td>\n",
       "      <td>1.123312</td>\n",
       "      <td>1.437643</td>\n",
       "      <td>...</td>\n",
       "      <td>1.139818</td>\n",
       "      <td>1.238471</td>\n",
       "      <td>1.196844</td>\n",
       "      <td>1.118109</td>\n",
       "      <td>1.111701</td>\n",
       "      <td>1.591664</td>\n",
       "      <td>1.143378</td>\n",
       "      <td>1.242899</td>\n",
       "      <td>1.337912</td>\n",
       "      <td>1.370505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.566485</td>\n",
       "      <td>16.289445</td>\n",
       "      <td>15.247593</td>\n",
       "      <td>14.408506</td>\n",
       "      <td>14.970660</td>\n",
       "      <td>14.526786</td>\n",
       "      <td>14.430398</td>\n",
       "      <td>14.516758</td>\n",
       "      <td>14.286098</td>\n",
       "      <td>13.278705</td>\n",
       "      <td>...</td>\n",
       "      <td>15.028946</td>\n",
       "      <td>14.327433</td>\n",
       "      <td>14.590482</td>\n",
       "      <td>14.083975</td>\n",
       "      <td>14.629420</td>\n",
       "      <td>13.412346</td>\n",
       "      <td>15.252446</td>\n",
       "      <td>14.718518</td>\n",
       "      <td>14.142212</td>\n",
       "      <td>13.527193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             TR4190        TR4184        TR4193        TR4186        TR4185  \\\n",
       "count  57736.000000  57736.000000  57736.000000  57736.000000  57736.000000   \n",
       "mean       1.194206      1.338851      1.171084      1.233508      1.238979   \n",
       "std        1.145634      1.292237      1.097246      1.157664      1.184453   \n",
       "min        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "25%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "50%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "75%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "max       14.566485     16.289445     15.247593     14.408506     14.970660   \n",
       "\n",
       "             TR4219        TR4268        TR4269        TR4271        TR4273  \\\n",
       "count  57736.000000  57736.000000  57736.000000  57736.000000  57736.000000   \n",
       "mean       1.281862      1.404603      1.240871      1.188165      1.385383   \n",
       "std        1.203927      1.447374      1.170842      1.123312      1.437643   \n",
       "min        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "25%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "50%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "75%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "max       14.526786     14.430398     14.516758     14.286098     13.278705   \n",
       "\n",
       "       ...        TR4191        TR4017        TR4329        TR4215  \\\n",
       "count  ...  57736.000000  57736.000000  57736.000000  57736.000000   \n",
       "mean   ...      1.175039      1.339240      1.198407      1.205923   \n",
       "std    ...      1.139818      1.238471      1.196844      1.118109   \n",
       "min    ...      0.873160      0.873160      0.873160      0.873160   \n",
       "25%    ...      0.873160      0.873160      0.873160      0.873160   \n",
       "50%    ...      0.873160      0.873160      0.873160      0.873160   \n",
       "75%    ...      0.873160      0.873160      0.873160      0.873160   \n",
       "max    ...     15.028946     14.327433     14.590482     14.083975   \n",
       "\n",
       "             TR4189        TR4011        TR4044        TR4267        TR4149  \\\n",
       "count  57736.000000  57736.000000  57736.000000  57736.000000  57736.000000   \n",
       "mean       1.196342      1.547039      1.202872      1.283150      1.265179   \n",
       "std        1.111701      1.591664      1.143378      1.242899      1.337912   \n",
       "min        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "25%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "50%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "75%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "max       14.629420     13.412346     15.252446     14.718518     14.142212   \n",
       "\n",
       "             TR4188  \n",
       "count  57736.000000  \n",
       "mean       1.345267  \n",
       "std        1.370505  \n",
       "min        0.873160  \n",
       "25%        0.873160  \n",
       "50%        0.873160  \n",
       "75%        0.873160  \n",
       "max       13.527193  \n",
       "\n",
       "[8 rows x 69 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TR4190</th>\n",
       "      <th>TR4184</th>\n",
       "      <th>TR4193</th>\n",
       "      <th>TR4186</th>\n",
       "      <th>TR4185</th>\n",
       "      <th>TR4219</th>\n",
       "      <th>TR4268</th>\n",
       "      <th>TR4269</th>\n",
       "      <th>TR4271</th>\n",
       "      <th>TR4273</th>\n",
       "      <th>...</th>\n",
       "      <th>TR4191</th>\n",
       "      <th>TR4017</th>\n",
       "      <th>TR4329</th>\n",
       "      <th>TR4215</th>\n",
       "      <th>TR4189</th>\n",
       "      <th>TR4011</th>\n",
       "      <th>TR4044</th>\n",
       "      <th>TR4267</th>\n",
       "      <th>TR4149</th>\n",
       "      <th>TR4188</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.074218</td>\n",
       "      <td>1.466389</td>\n",
       "      <td>1.293475</td>\n",
       "      <td>1.369223</td>\n",
       "      <td>1.608798</td>\n",
       "      <td>1.138521</td>\n",
       "      <td>1.082749</td>\n",
       "      <td>1.142271</td>\n",
       "      <td>1.268538</td>\n",
       "      <td>1.430429</td>\n",
       "      <td>...</td>\n",
       "      <td>1.370800</td>\n",
       "      <td>1.365978</td>\n",
       "      <td>1.314876</td>\n",
       "      <td>1.129716</td>\n",
       "      <td>1.355922</td>\n",
       "      <td>1.350276</td>\n",
       "      <td>1.146059</td>\n",
       "      <td>1.470701</td>\n",
       "      <td>1.484422</td>\n",
       "      <td>1.444118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.788013</td>\n",
       "      <td>2.307459</td>\n",
       "      <td>1.576355</td>\n",
       "      <td>1.940696</td>\n",
       "      <td>2.646473</td>\n",
       "      <td>1.083133</td>\n",
       "      <td>0.956349</td>\n",
       "      <td>1.055396</td>\n",
       "      <td>1.484436</td>\n",
       "      <td>2.332082</td>\n",
       "      <td>...</td>\n",
       "      <td>1.884220</td>\n",
       "      <td>1.804007</td>\n",
       "      <td>1.765342</td>\n",
       "      <td>1.041269</td>\n",
       "      <td>1.836795</td>\n",
       "      <td>1.966122</td>\n",
       "      <td>1.107575</td>\n",
       "      <td>2.298373</td>\n",
       "      <td>2.357991</td>\n",
       "      <td>2.293154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.690738</td>\n",
       "      <td>19.344109</td>\n",
       "      <td>12.999970</td>\n",
       "      <td>17.029339</td>\n",
       "      <td>22.010338</td>\n",
       "      <td>9.640545</td>\n",
       "      <td>9.076724</td>\n",
       "      <td>10.537092</td>\n",
       "      <td>13.403953</td>\n",
       "      <td>19.136480</td>\n",
       "      <td>...</td>\n",
       "      <td>15.758722</td>\n",
       "      <td>13.027126</td>\n",
       "      <td>14.900488</td>\n",
       "      <td>9.546752</td>\n",
       "      <td>14.753994</td>\n",
       "      <td>17.166380</td>\n",
       "      <td>11.719974</td>\n",
       "      <td>18.790796</td>\n",
       "      <td>18.779106</td>\n",
       "      <td>23.107731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             TR4190        TR4184        TR4193        TR4186        TR4185  \\\n",
       "count  57736.000000  57736.000000  57736.000000  57736.000000  57736.000000   \n",
       "mean       1.074218      1.466389      1.293475      1.369223      1.608798   \n",
       "std        0.788013      2.307459      1.576355      1.940696      2.646473   \n",
       "min        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "25%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "50%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "75%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "max        6.690738     19.344109     12.999970     17.029339     22.010338   \n",
       "\n",
       "             TR4219        TR4268        TR4269        TR4271        TR4273  \\\n",
       "count  57736.000000  57736.000000  57736.000000  57736.000000  57736.000000   \n",
       "mean       1.138521      1.082749      1.142271      1.268538      1.430429   \n",
       "std        1.083133      0.956349      1.055396      1.484436      2.332082   \n",
       "min        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "25%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "50%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "75%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "max        9.640545      9.076724     10.537092     13.403953     19.136480   \n",
       "\n",
       "       ...        TR4191        TR4017        TR4329        TR4215  \\\n",
       "count  ...  57736.000000  57736.000000  57736.000000  57736.000000   \n",
       "mean   ...      1.370800      1.365978      1.314876      1.129716   \n",
       "std    ...      1.884220      1.804007      1.765342      1.041269   \n",
       "min    ...      0.873160      0.873160      0.873160      0.873160   \n",
       "25%    ...      0.873160      0.873160      0.873160      0.873160   \n",
       "50%    ...      0.873160      0.873160      0.873160      0.873160   \n",
       "75%    ...      0.873160      0.873160      0.873160      0.873160   \n",
       "max    ...     15.758722     13.027126     14.900488      9.546752   \n",
       "\n",
       "             TR4189        TR4011        TR4044        TR4267        TR4149  \\\n",
       "count  57736.000000  57736.000000  57736.000000  57736.000000  57736.000000   \n",
       "mean       1.355922      1.350276      1.146059      1.470701      1.484422   \n",
       "std        1.836795      1.966122      1.107575      2.298373      2.357991   \n",
       "min        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "25%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "50%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "75%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "max       14.753994     17.166380     11.719974     18.790796     18.779106   \n",
       "\n",
       "             TR4188  \n",
       "count  57736.000000  \n",
       "mean       1.444118  \n",
       "std        2.293154  \n",
       "min        0.873160  \n",
       "25%        0.873160  \n",
       "50%        0.873160  \n",
       "75%        0.873160  \n",
       "max       23.107731  \n",
       "\n",
       "[8 rows x 69 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "krzysiu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
