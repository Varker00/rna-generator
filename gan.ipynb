{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models, optimizers\n",
    "from keras.layers import Dense, LSTM, Embedding, LeakyReLU, BatchNormalization, Dropout, Input, ReLU\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57736, 69)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data_path = 'original_data/GSE158508_normalized_counts.tsv'\n",
    "data = pd.read_csv(data_path, sep='\\t', index_col=0)\n",
    "\n",
    "data_shape = data.shape[1]  # 69 columns\n",
    "\n",
    "# Save columns names for later use\n",
    "col_names = data.columns.values\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(latent_dim, data_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(64, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "    model.add(Dense(64, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    model.add(Dense(128))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "    model.add(Dense(2048))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "    model.add(Dense(4096))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    model.add(Dense(data_shape, activation='relu'))\n",
    "    \n",
    "    noise = Input(shape=(latent_dim,))\n",
    "    generated_data = model(noise)\n",
    "    \n",
    "    return Model(noise, generated_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(data_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(1024, input_dim=data_shape))\n",
    "    model.add(ReLU())\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Dense(1024))\n",
    "    model.add(ReLU())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(512))\n",
    "    model.add(ReLU())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(256))\n",
    "    model.add(ReLU())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(ReLU())\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    data = Input(shape=(data_shape,))\n",
    "    validity = model(data)\n",
    "    \n",
    "    return Model(data, validity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wymiary przestrzeni ukrytej\n",
    "latent_dim = 64\n",
    "\n",
    "# Budowa i kompilacja dyskryminatora\n",
    "discriminator = build_discriminator(data_shape)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "\n",
    "# Budowa generatora\n",
    "generator = build_generator(latent_dim, data_shape)\n",
    "\n",
    "# Generator bierze szum jako wejście i generuje dane\n",
    "z = Input(shape=(latent_dim,))\n",
    "generated_data = generator(z)\n",
    "\n",
    "# Tylko generator jest trenowany\n",
    "discriminator.trainable = False\n",
    "\n",
    "# Dyskryminator bierze wygenerowane dane jako wejście i określa ich prawdziwość\n",
    "validity = discriminator(generated_data)\n",
    "\n",
    "# Połączony model (stacked generator and discriminator)\n",
    "combined = Model(z, validity)\n",
    "combined.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_dir = './training_checkpoints'\n",
    "# checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "# checkpoint = tf.train.Checkpoint(generator=generator,\n",
    "#                                  discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_output(generated_data):\n",
    "    min_val = 0.873159932419581\n",
    "    return generated_data + min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, combined, data, latent_dim, epochs, batch_size=128, save_interval=50):\n",
    "    # Ładowanie i skalowanie danych\n",
    "    X_train = data.values\n",
    "\n",
    "    # Pętla po epokach\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        # ---------------------\n",
    "        #  Trenowanie dyskryminatora\n",
    "        # ---------------------\n",
    "\n",
    "        # Wybieranie losowych próbek\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        real_data = X_train[idx]\n",
    "\n",
    "        # Generowanie nowego szumu\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "\n",
    "        # Generowanie nowych danych\n",
    "        generated_data = generator.predict(noise)\n",
    "        generated_data = scale_output(generated_data)\n",
    "\n",
    "        # Trenowanie dyskryminatora\n",
    "        d_loss_real = discriminator.train_on_batch(real_data, np.ones((batch_size, 1)))\n",
    "        d_loss_fake = discriminator.train_on_batch(generated_data, np.zeros((batch_size, 1)))\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Trenowanie generatora\n",
    "        # ---------------------\n",
    "\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "\n",
    "        # Chcemy, aby dyskryminator uznał wygenerowane dane za prawdziwe\n",
    "        valid_y = np.array([1] * batch_size)\n",
    "\n",
    "        # Trenowanie generatora\n",
    "        g_loss = combined.train_on_batch(noise, valid_y)\n",
    "\n",
    "        # Zapisywanie postępów\n",
    "        if epoch % save_interval == 0:\n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "            print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "            #checkpoint.save(file_prefix = checkpoint_prefix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.852849, acc.: 26.93%] [G loss: 0.629460]\n",
      "Time for epoch 1 is 4.526929616928101 sec\n",
      "50 [D loss: 0.697878, acc.: 49.32%] [G loss: 0.721198]\n",
      "Time for epoch 51 is 0.8264892101287842 sec\n",
      "100 [D loss: 0.695164, acc.: 50.98%] [G loss: 0.698274]\n",
      "Time for epoch 101 is 0.8019261360168457 sec\n",
      "150 [D loss: 0.692809, acc.: 52.12%] [G loss: 0.693293]\n",
      "Time for epoch 151 is 0.797844409942627 sec\n",
      "200 [D loss: 0.696308, acc.: 51.81%] [G loss: 0.694075]\n",
      "Time for epoch 201 is 1.1123497486114502 sec\n",
      "250 [D loss: 0.692505, acc.: 53.22%] [G loss: 0.694788]\n",
      "Time for epoch 251 is 1.3819751739501953 sec\n",
      "300 [D loss: 0.694990, acc.: 51.39%] [G loss: 0.692912]\n",
      "Time for epoch 301 is 1.0467572212219238 sec\n",
      "350 [D loss: 0.693592, acc.: 50.95%] [G loss: 0.696139]\n",
      "Time for epoch 351 is 1.0929861068725586 sec\n",
      "400 [D loss: 0.694290, acc.: 47.71%] [G loss: 0.693498]\n",
      "Time for epoch 401 is 1.134448528289795 sec\n",
      "450 [D loss: 0.693870, acc.: 48.34%] [G loss: 0.690891]\n",
      "Time for epoch 451 is 1.0806210041046143 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Repositories\\rna-generator\\gan.ipynb Cell 17\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repositories/rna-generator/gan.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Trenowanie modelu\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Repositories/rna-generator/gan.ipynb#X53sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train(generator, discriminator, combined, data, latent_dim, epochs\u001b[39m=\u001b[39;49m\u001b[39m3000\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m2048\u001b[39;49m)\n",
      "\u001b[1;32md:\\Repositories\\rna-generator\\gan.ipynb Cell 17\u001b[0m line \u001b[0;36mtrain\u001b[1;34m(generator, discriminator, combined, data, latent_dim, epochs, batch_size, save_interval)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repositories/rna-generator/gan.ipynb#X53sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m noise \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, (batch_size, latent_dim))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repositories/rna-generator/gan.ipynb#X53sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Generowanie nowych danych\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Repositories/rna-generator/gan.ipynb#X53sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m generated_data \u001b[39m=\u001b[39m generator\u001b[39m.\u001b[39;49mpredict(noise)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repositories/rna-generator/gan.ipynb#X53sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m generated_data \u001b[39m=\u001b[39m scale_output(generated_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repositories/rna-generator/gan.ipynb#X53sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Trenowanie dyskryminatora\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py:1982\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1980\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[0;32m   1981\u001b[0m   callbacks\u001b[39m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m-> 1982\u001b[0m   tmp_batch_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_function(iterator)\n\u001b[0;32m   1983\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1984\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2957\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1854\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Trenowanie modelu\n",
    "train(generator, discriminator, combined, data, latent_dim, epochs=3000, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate after the final epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(generator, n_samples):\n",
    "    noise = np.random.normal(0, 1, size=(n_samples, latent_dim))\n",
    "    generated_data = generator.predict(noise)\n",
    "    generated_data = scale_output(generated_data)\n",
    "    return generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data = generate_data(generator, n_samples=57736)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the generated data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(synthetic_data)\n",
    "# append column names to the data \n",
    "df.columns = col_names\n",
    "df.to_csv('synthetic_data/generated_data.tsv', sep='\\t', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TR4190</th>\n",
       "      <th>TR4184</th>\n",
       "      <th>TR4193</th>\n",
       "      <th>TR4186</th>\n",
       "      <th>TR4185</th>\n",
       "      <th>TR4219</th>\n",
       "      <th>TR4268</th>\n",
       "      <th>TR4269</th>\n",
       "      <th>TR4271</th>\n",
       "      <th>TR4273</th>\n",
       "      <th>...</th>\n",
       "      <th>TR4191</th>\n",
       "      <th>TR4017</th>\n",
       "      <th>TR4329</th>\n",
       "      <th>TR4215</th>\n",
       "      <th>TR4189</th>\n",
       "      <th>TR4011</th>\n",
       "      <th>TR4044</th>\n",
       "      <th>TR4267</th>\n",
       "      <th>TR4149</th>\n",
       "      <th>TR4188</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.194206</td>\n",
       "      <td>1.338851</td>\n",
       "      <td>1.171084</td>\n",
       "      <td>1.233508</td>\n",
       "      <td>1.238979</td>\n",
       "      <td>1.281862</td>\n",
       "      <td>1.404603</td>\n",
       "      <td>1.240871</td>\n",
       "      <td>1.188165</td>\n",
       "      <td>1.385383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.175039</td>\n",
       "      <td>1.339240</td>\n",
       "      <td>1.198407</td>\n",
       "      <td>1.205923</td>\n",
       "      <td>1.196342</td>\n",
       "      <td>1.547039</td>\n",
       "      <td>1.202872</td>\n",
       "      <td>1.283150</td>\n",
       "      <td>1.265179</td>\n",
       "      <td>1.345267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.145634</td>\n",
       "      <td>1.292237</td>\n",
       "      <td>1.097246</td>\n",
       "      <td>1.157664</td>\n",
       "      <td>1.184453</td>\n",
       "      <td>1.203927</td>\n",
       "      <td>1.447374</td>\n",
       "      <td>1.170842</td>\n",
       "      <td>1.123312</td>\n",
       "      <td>1.437643</td>\n",
       "      <td>...</td>\n",
       "      <td>1.139818</td>\n",
       "      <td>1.238471</td>\n",
       "      <td>1.196844</td>\n",
       "      <td>1.118109</td>\n",
       "      <td>1.111701</td>\n",
       "      <td>1.591664</td>\n",
       "      <td>1.143378</td>\n",
       "      <td>1.242899</td>\n",
       "      <td>1.337912</td>\n",
       "      <td>1.370505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.566485</td>\n",
       "      <td>16.289445</td>\n",
       "      <td>15.247593</td>\n",
       "      <td>14.408506</td>\n",
       "      <td>14.970660</td>\n",
       "      <td>14.526786</td>\n",
       "      <td>14.430398</td>\n",
       "      <td>14.516758</td>\n",
       "      <td>14.286098</td>\n",
       "      <td>13.278705</td>\n",
       "      <td>...</td>\n",
       "      <td>15.028946</td>\n",
       "      <td>14.327433</td>\n",
       "      <td>14.590482</td>\n",
       "      <td>14.083975</td>\n",
       "      <td>14.629420</td>\n",
       "      <td>13.412346</td>\n",
       "      <td>15.252446</td>\n",
       "      <td>14.718518</td>\n",
       "      <td>14.142212</td>\n",
       "      <td>13.527193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             TR4190        TR4184        TR4193        TR4186        TR4185  \\\n",
       "count  57736.000000  57736.000000  57736.000000  57736.000000  57736.000000   \n",
       "mean       1.194206      1.338851      1.171084      1.233508      1.238979   \n",
       "std        1.145634      1.292237      1.097246      1.157664      1.184453   \n",
       "min        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "25%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "50%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "75%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "max       14.566485     16.289445     15.247593     14.408506     14.970660   \n",
       "\n",
       "             TR4219        TR4268        TR4269        TR4271        TR4273  \\\n",
       "count  57736.000000  57736.000000  57736.000000  57736.000000  57736.000000   \n",
       "mean       1.281862      1.404603      1.240871      1.188165      1.385383   \n",
       "std        1.203927      1.447374      1.170842      1.123312      1.437643   \n",
       "min        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "25%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "50%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "75%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "max       14.526786     14.430398     14.516758     14.286098     13.278705   \n",
       "\n",
       "       ...        TR4191        TR4017        TR4329        TR4215  \\\n",
       "count  ...  57736.000000  57736.000000  57736.000000  57736.000000   \n",
       "mean   ...      1.175039      1.339240      1.198407      1.205923   \n",
       "std    ...      1.139818      1.238471      1.196844      1.118109   \n",
       "min    ...      0.873160      0.873160      0.873160      0.873160   \n",
       "25%    ...      0.873160      0.873160      0.873160      0.873160   \n",
       "50%    ...      0.873160      0.873160      0.873160      0.873160   \n",
       "75%    ...      0.873160      0.873160      0.873160      0.873160   \n",
       "max    ...     15.028946     14.327433     14.590482     14.083975   \n",
       "\n",
       "             TR4189        TR4011        TR4044        TR4267        TR4149  \\\n",
       "count  57736.000000  57736.000000  57736.000000  57736.000000  57736.000000   \n",
       "mean       1.196342      1.547039      1.202872      1.283150      1.265179   \n",
       "std        1.111701      1.591664      1.143378      1.242899      1.337912   \n",
       "min        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "25%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "50%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "75%        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "max       14.629420     13.412346     15.252446     14.718518     14.142212   \n",
       "\n",
       "             TR4188  \n",
       "count  57736.000000  \n",
       "mean       1.345267  \n",
       "std        1.370505  \n",
       "min        0.873160  \n",
       "25%        0.873160  \n",
       "50%        0.873160  \n",
       "75%        0.873160  \n",
       "max       13.527193  \n",
       "\n",
       "[8 rows x 69 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TR4190</th>\n",
       "      <th>TR4184</th>\n",
       "      <th>TR4193</th>\n",
       "      <th>TR4186</th>\n",
       "      <th>TR4185</th>\n",
       "      <th>TR4219</th>\n",
       "      <th>TR4268</th>\n",
       "      <th>TR4269</th>\n",
       "      <th>TR4271</th>\n",
       "      <th>TR4273</th>\n",
       "      <th>...</th>\n",
       "      <th>TR4191</th>\n",
       "      <th>TR4017</th>\n",
       "      <th>TR4329</th>\n",
       "      <th>TR4215</th>\n",
       "      <th>TR4189</th>\n",
       "      <th>TR4011</th>\n",
       "      <th>TR4044</th>\n",
       "      <th>TR4267</th>\n",
       "      <th>TR4149</th>\n",
       "      <th>TR4188</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "      <td>57736.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.051405</td>\n",
       "      <td>1.597122</td>\n",
       "      <td>0.873176</td>\n",
       "      <td>0.980953</td>\n",
       "      <td>0.897371</td>\n",
       "      <td>1.964139</td>\n",
       "      <td>1.400752</td>\n",
       "      <td>1.173359</td>\n",
       "      <td>0.877007</td>\n",
       "      <td>1.851400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>1.046476</td>\n",
       "      <td>1.555990</td>\n",
       "      <td>1.626892</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>1.925425</td>\n",
       "      <td>1.038716</td>\n",
       "      <td>0.886786</td>\n",
       "      <td>0.873191</td>\n",
       "      <td>0.962128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.775961</td>\n",
       "      <td>0.699174</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>0.263535</td>\n",
       "      <td>0.103911</td>\n",
       "      <td>0.705737</td>\n",
       "      <td>0.779746</td>\n",
       "      <td>0.543532</td>\n",
       "      <td>0.025109</td>\n",
       "      <td>0.951902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.341178</td>\n",
       "      <td>0.693108</td>\n",
       "      <td>0.558726</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.741452</td>\n",
       "      <td>0.325553</td>\n",
       "      <td>0.074302</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>0.266894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.477926</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>1.341336</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.903075</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.981285</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.186714</td>\n",
       "      <td>1.504515</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>2.139694</td>\n",
       "      <td>0.887716</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>1.728293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>1.408911</td>\n",
       "      <td>1.693339</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>2.050710</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.632104</td>\n",
       "      <td>2.042601</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>2.492109</td>\n",
       "      <td>1.748798</td>\n",
       "      <td>1.279757</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>2.401282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>1.078574</td>\n",
       "      <td>2.005128</td>\n",
       "      <td>2.009491</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>2.455536</td>\n",
       "      <td>1.046527</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.873160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.092374</td>\n",
       "      <td>4.765678</td>\n",
       "      <td>1.014402</td>\n",
       "      <td>2.889914</td>\n",
       "      <td>2.222526</td>\n",
       "      <td>3.466793</td>\n",
       "      <td>6.070132</td>\n",
       "      <td>5.337439</td>\n",
       "      <td>1.462217</td>\n",
       "      <td>7.334809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891643</td>\n",
       "      <td>4.602888</td>\n",
       "      <td>4.616714</td>\n",
       "      <td>3.945812</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>4.092665</td>\n",
       "      <td>3.023783</td>\n",
       "      <td>2.006119</td>\n",
       "      <td>1.246375</td>\n",
       "      <td>3.235507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             TR4190        TR4184        TR4193        TR4186        TR4185  \\\n",
       "count  57736.000000  57736.000000  57736.000000  57736.000000  57736.000000   \n",
       "mean       2.051405      1.597122      0.873176      0.980953      0.897371   \n",
       "std        0.775961      0.699174      0.001403      0.263535      0.103911   \n",
       "min        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "25%        1.477926      0.873160      0.873160      0.873160      0.873160   \n",
       "50%        2.186714      1.504515      0.873160      0.873160      0.873160   \n",
       "75%        2.632104      2.042601      0.873160      0.873160      0.873160   \n",
       "max        4.092374      4.765678      1.014402      2.889914      2.222526   \n",
       "\n",
       "             TR4219        TR4268        TR4269        TR4271        TR4273  \\\n",
       "count  57736.000000  57736.000000  57736.000000  57736.000000  57736.000000   \n",
       "mean       1.964139      1.400752      1.173359      0.877007      1.851400   \n",
       "std        0.705737      0.779746      0.543532      0.025109      0.951902   \n",
       "min        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "25%        1.341336      0.873160      0.873160      0.873160      0.873160   \n",
       "50%        2.139694      0.887716      0.873160      0.873160      1.728293   \n",
       "75%        2.492109      1.748798      1.279757      0.873160      2.401282   \n",
       "max        3.466793      6.070132      5.337439      1.462217      7.334809   \n",
       "\n",
       "       ...        TR4191        TR4017        TR4329        TR4215  \\\n",
       "count  ...  57736.000000  57736.000000  57736.000000  57736.000000   \n",
       "mean   ...      0.873160      1.046476      1.555990      1.626892   \n",
       "std    ...      0.000580      0.341178      0.693108      0.558726   \n",
       "min    ...      0.873160      0.873160      0.873160      0.873160   \n",
       "25%    ...      0.873160      0.873160      0.873160      0.903075   \n",
       "50%    ...      0.873160      0.873160      1.408911      1.693339   \n",
       "75%    ...      0.873160      1.078574      2.005128      2.009491   \n",
       "max    ...      0.891643      4.602888      4.616714      3.945812   \n",
       "\n",
       "             TR4189        TR4011        TR4044        TR4267        TR4149  \\\n",
       "count  57736.000000  57736.000000  57736.000000  57736.000000  57736.000000   \n",
       "mean       0.873160      1.925425      1.038716      0.886786      0.873191   \n",
       "std        0.000575      0.741452      0.325553      0.074302      0.002596   \n",
       "min        0.873160      0.873160      0.873160      0.873160      0.873160   \n",
       "25%        0.873160      0.981285      0.873160      0.873160      0.873160   \n",
       "50%        0.873160      2.050710      0.873160      0.873160      0.873160   \n",
       "75%        0.873160      2.455536      1.046527      0.873160      0.873160   \n",
       "max        0.873160      4.092665      3.023783      2.006119      1.246375   \n",
       "\n",
       "             TR4188  \n",
       "count  57736.000000  \n",
       "mean       0.962128  \n",
       "std        0.266894  \n",
       "min        0.873160  \n",
       "25%        0.873160  \n",
       "50%        0.873160  \n",
       "75%        0.873160  \n",
       "max        3.235507  \n",
       "\n",
       "[8 rows x 69 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "krzysiu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
